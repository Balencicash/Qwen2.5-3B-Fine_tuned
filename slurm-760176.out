run sh: `/home3/sgrf64/venv_python310/bin/python /home3/sgrf64/venv_python310/lib/python3.10/site-packages/swift/cli/eval.py --model Qwen/Qwen2.5-3B --eval_backend Native --infer_backend pt --eval_output_dir eval_output/native/qwen2.5_3B_baseline --temperature 0.7 --max_new_tokens 256 --top_p 0.9 --repetition_penalty 1.2 --eval_limit 5 --eval_dataset mmlu`
[INFO:swift] Successfully registered `/home3/sgrf64/venv_python310/lib/python3.10/site-packages/swift/llm/dataset/data/dataset_info.json`.
[INFO:swift] rank: -1, local_rank: -1, world_size: 1, local_world_size: 1
[INFO:swift.hub.hub] Downloading the model from ModelScope Hub, model_id: Qwen/Qwen2.5-3B
[INFO:swift] Loading the model using model_dir: /home3/sgrf64/.cache/modelscope/hub/models/Qwen/Qwen2___5-3B
[INFO:swift] Setting torch_dtype: torch.bfloat16
[INFO:swift] args.result_path: /home3/sgrf64/Project/qwen_finetune/result/Qwen2.5-3B/eval_result/20250512-155541.jsonl
[INFO:swift] eval_backend: Native
[INFO:swift] eval_dataset: ['mmlu']
[INFO:swift] eval_output_dir: /home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline
[INFO:swift] Global seed set to 42
[INFO:swift] args: EvalArguments(model='Qwen/Qwen2.5-3B', model_type='qwen2_5', model_revision=None, task_type='causal_lm', torch_dtype=torch.bfloat16, attn_impl=None, num_labels=None, problem_type=None, rope_scaling=None, device_map=None, max_memory={}, local_repo_path=None, template='qwen2_5', system=None, max_length=None, truncation_strategy='delete', max_pixels=None, agent_template=None, norm_bbox=None, response_prefix=None, padding_side='right', loss_scale='default', sequence_parallel_size=1, use_chat_template=True, template_backend='swift', dataset=[], val_dataset=[], split_dataset_ratio=0.01, data_seed=42, dataset_num_proc=1, dataset_shuffle=True, val_dataset_shuffle=False, streaming=False, interleave_prob=None, stopping_strategy='first_exhausted', shuffle_buffer_size=1000, enable_cache=False, download_mode='reuse_dataset_if_exists', columns={}, strict=False, remove_unused_columns=True, model_name=[None, None], model_author=[None, None], custom_dataset_info=[], quant_method=None, quant_bits=None, hqq_axis=None, bnb_4bit_compute_dtype=torch.bfloat16, bnb_4bit_quant_type='nf4', bnb_4bit_use_double_quant=True, bnb_4bit_quant_storage=None, max_new_tokens=256, temperature=0.7, top_k=None, top_p=0.9, repetition_penalty=1.2, num_beams=1, stream=False, stop_words=[], logprobs=False, top_logprobs=None, ckpt_dir=None, load_dataset_config=None, lora_modules=[], tuner_backend='peft', train_type='lora', adapters=[], external_plugins=[], seed=42, model_kwargs={}, load_args=True, load_data_args=False, use_hf=False, hub_token=None, custom_register_path=[], ignore_args_error=False, use_swift_lora=False, tp=1, session_len=None, cache_max_entry_count=0.8, quant_policy=0, vision_batch_size=1, gpu_memory_utilization=0.9, tensor_parallel_size=1, pipeline_parallel_size=1, max_num_seqs=256, max_model_len=None, disable_custom_all_reduce=False, enforce_eager=False, limit_mm_per_prompt={}, vllm_max_lora_rank=16, enable_prefix_caching=False, use_async_engine=True, data_parallel_size=1, log_level='info', vllm_quantization=None, merge_lora=False, safe_serialization=True, max_shard_size='5GB', infer_backend='pt', result_path='/home3/sgrf64/Project/qwen_finetune/result/Qwen2.5-3B/eval_result/20250512-155541.jsonl', metric=None, max_batch_size=1, ddp_backend=None, val_dataset_sample=None, host='0.0.0.0', port=8000, api_key=None, ssl_keyfile=None, ssl_certfile=None, owned_by='swift', served_model_name=None, verbose=False, log_interval=20, max_logprobs=20, eval_dataset=['mmlu'], eval_limit=5, dataset_args={}, eval_output_dir='/home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline', eval_backend='Native', local_dataset=False, eval_num_proc=16, eval_url=None)
[INFO:swift] Start time of running main: 2025-05-12 15:55:59.715213
[INFO:swift] rank: -1, local_rank: -1, world_size: 1, local_world_size: 1
[INFO:swift.hub.hub] Downloading the model from ModelScope Hub, model_id: Qwen/Qwen2.5-3B
[INFO:swift] Loading the model using model_dir: /home3/sgrf64/.cache/modelscope/hub/models/Qwen/Qwen2___5-3B
Downloading Model from https://www.modelscope.cn to directory: /home3/sgrf64/.cache/modelscope/hub/models/Qwen/Qwen2.5-3B
ANTLR runtime and generated code versions disagree: 4.9.3!=4.7.2
ANTLR runtime and generated code versions disagree: 4.9.3!=4.7.2
ANTLR runtime and generated code versions disagree: 4.9.3!=4.7.2
ANTLR runtime and generated code versions disagree: 4.9.3!=4.7.2
Downloading Model from https://www.modelscope.cn to directory: /home3/sgrf64/.cache/modelscope/hub/models/Qwen/Qwen2.5-3B
[INFO:swift] Successfully registered `/home3/sgrf64/venv_python310/lib/python3.10/site-packages/swift/llm/dataset/data/dataset_info.json`.
[INFO:swift] Global seed set to 42
[INFO:swift] args: DeployArguments(model='Qwen/Qwen2.5-3B', model_type='qwen2_5', model_revision=None, task_type='causal_lm', torch_dtype=torch.bfloat16, attn_impl=None, num_labels=None, problem_type=None, rope_scaling=None, device_map=None, max_memory={}, local_repo_path=None, template='qwen2_5', system=None, max_length=None, truncation_strategy='delete', max_pixels=None, agent_template=None, norm_bbox=None, response_prefix=None, padding_side='right', loss_scale='default', sequence_parallel_size=1, use_chat_template=True, template_backend='swift', dataset=[], val_dataset=[], split_dataset_ratio=0.01, data_seed=42, dataset_num_proc=1, dataset_shuffle=True, val_dataset_shuffle=False, streaming=False, interleave_prob=None, stopping_strategy='first_exhausted', shuffle_buffer_size=1000, enable_cache=False, download_mode='reuse_dataset_if_exists', columns={}, strict=False, remove_unused_columns=True, model_name=[None, None], model_author=[None, None], custom_dataset_info=[], quant_method=None, quant_bits=None, hqq_axis=None, bnb_4bit_compute_dtype=torch.bfloat16, bnb_4bit_quant_type='nf4', bnb_4bit_use_double_quant=True, bnb_4bit_quant_storage=None, max_new_tokens=256, temperature=0.7, top_k=None, top_p=0.9, repetition_penalty=1.2, num_beams=1, stream=False, stop_words=[], logprobs=False, top_logprobs=None, ckpt_dir=None, load_dataset_config=None, lora_modules=[], tuner_backend='peft', train_type='lora', adapters=[], external_plugins=[], seed=42, model_kwargs={}, load_args=True, load_data_args=False, use_hf=False, hub_token=None, custom_register_path=[], ignore_args_error=False, use_swift_lora=False, tp=1, session_len=None, cache_max_entry_count=0.8, quant_policy=0, vision_batch_size=1, gpu_memory_utilization=0.9, tensor_parallel_size=1, pipeline_parallel_size=1, max_num_seqs=256, max_model_len=None, disable_custom_all_reduce=False, enforce_eager=False, limit_mm_per_prompt={}, vllm_max_lora_rank=16, enable_prefix_caching=False, use_async_engine=True, data_parallel_size=1, log_level='info', vllm_quantization=None, merge_lora=False, safe_serialization=True, max_shard_size='5GB', infer_backend='pt', result_path='/home3/sgrf64/Project/qwen_finetune/result/Qwen2.5-3B/eval_result/20250512-155541.jsonl', metric=None, max_batch_size=1, ddp_backend=None, val_dataset_sample=None, host='0.0.0.0', port=8000, api_key=None, ssl_keyfile=None, ssl_certfile=None, owned_by='swift', served_model_name=None, verbose=False, log_interval=20, max_logprobs=20)
[INFO:swift.hub.hub] Downloading the model from ModelScope Hub, model_id: Qwen/Qwen2.5-3B
[INFO:swift] Loading the model using model_dir: /home3/sgrf64/.cache/modelscope/hub/models/Qwen/Qwen2___5-3B
[INFO:swift] model_kwargs: {'device_map': 'cuda:0'}
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
Downloading Model from https://www.modelscope.cn to directory: /home3/sgrf64/.cache/modelscope/hub/models/Qwen/Qwen2.5-3B
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [01:19<01:19, 79.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [02:00<00:00, 57.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [02:00<00:00, 60.50s/it]
[INFO:swift] default_system: 'You are Qwen, created by Alibaba Cloud. You are a helpful assistant.'
[INFO:swift] response_prefix: ''
[INFO:swift] agent_template: hermes
[INFO:swift] max_length: 32768
[INFO:swift] norm_bbox: norm1000
[INFO:swift] model: Qwen2ForCausalLM(
  (model): Qwen2Model(
    (embed_tokens): Embedding(151936, 2048)
    (layers): ModuleList(
      (0-35): 36 x Qwen2DecoderLayer(
        (self_attn): Qwen2Attention(
          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)
          (k_proj): Linear(in_features=2048, out_features=256, bias=True)
          (v_proj): Linear(in_features=2048, out_features=256, bias=True)
          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)
        )
        (mlp): Qwen2MLP(
          (gate_proj): Linear(in_features=2048, out_features=11008, bias=False)
          (up_proj): Linear(in_features=2048, out_features=11008, bias=False)
          (down_proj): Linear(in_features=11008, out_features=2048, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): Qwen2RMSNorm((2048,), eps=1e-06)
        (post_attention_layernorm): Qwen2RMSNorm((2048,), eps=1e-06)
      )
    )
    (norm): Qwen2RMSNorm((2048,), eps=1e-06)
    (rotary_emb): Qwen2RotaryEmbedding()
  )
  (lm_head): Linear(in_features=2048, out_features=151936, bias=False)
)
[INFO:swift] Start time of running main: 2025-05-12 15:58:22.467571
[INFO:swift] model_list: ['Qwen2.5-3B']
INFO:     Started server process [3156197]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
INFO:     127.0.0.1:56750 - "GET /v1/models HTTP/1.1" 200 OK
2025-05-12 15:58:25,108 - evalscope - INFO - Args: Task config is provided with TaskConfig type.
2025-05-12 15:58:27,365 - evalscope - INFO - Dump task config to /home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline/native/20250512_155825/configs/task_config_b69ebc.yaml
2025-05-12 15:58:27,410 - evalscope - INFO - {
    "model": "Qwen2.5-3B",
    "model_id": "Qwen2.5-3B",
    "model_args": {
        "revision": "master",
        "precision": "torch.float16"
    },
    "model_task": "text_generation",
    "template_type": null,
    "chat_template": null,
    "datasets": [
        "mmlu"
    ],
    "dataset_args": {
        "mmlu": {
            "name": "mmlu",
            "dataset_id": "modelscope/mmlu",
            "model_adapter": "generation",
            "output_types": [
                "multiple_choice_logits",
                "generation"
            ],
            "subset_list": [
                "high_school_european_history",
                "business_ethics",
                "clinical_knowledge",
                "medical_genetics",
                "high_school_us_history",
                "high_school_physics",
                "high_school_world_history",
                "virology",
                "high_school_microeconomics",
                "econometrics",
                "college_computer_science",
                "high_school_biology",
                "abstract_algebra",
                "professional_accounting",
                "philosophy",
                "professional_medicine",
                "nutrition",
                "global_facts",
                "machine_learning",
                "security_studies",
                "public_relations",
                "professional_psychology",
                "prehistory",
                "anatomy",
                "human_sexuality",
                "college_medicine",
                "high_school_government_and_politics",
                "college_chemistry",
                "logical_fallacies",
                "high_school_geography",
                "elementary_mathematics",
                "human_aging",
                "college_mathematics",
                "high_school_psychology",
                "formal_logic",
                "high_school_statistics",
                "international_law",
                "high_school_mathematics",
                "high_school_computer_science",
                "conceptual_physics",
                "miscellaneous",
                "high_school_chemistry",
                "marketing",
                "professional_law",
                "management",
                "college_physics",
                "jurisprudence",
                "world_religions",
                "sociology",
                "us_foreign_policy",
                "high_school_macroeconomics",
                "computer_security",
                "moral_scenarios",
                "moral_disputes",
                "electrical_engineering",
                "astronomy",
                "college_biology"
            ],
            "metric_list": [
                "AverageAccuracy"
            ],
            "few_shot_num": 5,
            "few_shot_random": false,
            "train_split": "train",
            "eval_split": "test",
            "prompt_template": "Answer the following multiple choice question about {subset_name}. The last line of your response should be of the following format: 'Answer: $LETTER' (without quotes) where LETTER is one of ABCD. Think step by step before answering.\n\n{query}",
            "system_prompt": null,
            "query_template": null,
            "pretty_name": "MMLU",
            "filters": null,
            "extra_params": {}
        }
    },
    "dataset_dir": "/home3/sgrf64/.cache/modelscope/hub/datasets",
    "dataset_hub": "modelscope",
    "generation_config": {
        "max_length": 2048,
        "max_new_tokens": 512,
        "do_sample": false,
        "top_k": 50,
        "top_p": 1.0,
        "temperature": 1.0
    },
    "eval_type": "service",
    "eval_backend": "Native",
    "eval_config": null,
    "stage": "all",
    "limit": 5,
    "eval_batch_size": 16,
    "mem_cache": false,
    "use_cache": null,
    "work_dir": "/home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline/native/20250512_155825",
    "outputs": null,
    "debug": false,
    "dry_run": false,
    "seed": 42,
    "api_url": "http://127.0.0.1:8000/v1/chat/completions",
    "api_key": "EMPTY",
    "timeout": null,
    "stream": false,
    "judge_strategy": "auto",
    "judge_worker_num": 1,
    "judge_model_args": {}
}
2025-05-12 15:58:27,411 - evalscope - INFO - **** Start evaluating on dataset modelscope/mmlu ****
2025-05-12 15:58:27,412 - evalscope - INFO - Loading dataset from hub: modelscope/mmlu
2025-05-12 15:58:29,302 - evalscope - INFO - Loading dataset: dataset_name: modelscope/mmlu > subsets: ['high_school_european_history', 'business_ethics', 'clinical_knowledge', 'medical_genetics', 'high_school_us_history', 'high_school_physics', 'high_school_world_history', 'virology', 'high_school_microeconomics', 'econometrics', 'college_computer_science', 'high_school_biology', 'abstract_algebra', 'professional_accounting', 'philosophy', 'professional_medicine', 'nutrition', 'global_facts', 'machine_learning', 'security_studies', 'public_relations', 'professional_psychology', 'prehistory', 'anatomy', 'human_sexuality', 'college_medicine', 'high_school_government_and_politics', 'college_chemistry', 'logical_fallacies', 'high_school_geography', 'elementary_mathematics', 'human_aging', 'college_mathematics', 'high_school_psychology', 'formal_logic', 'high_school_statistics', 'international_law', 'high_school_mathematics', 'high_school_computer_science', 'conceptual_physics', 'miscellaneous', 'high_school_chemistry', 'marketing', 'professional_law', 'management', 'college_physics', 'jurisprudence', 'world_religions', 'sociology', 'us_foreign_policy', 'high_school_macroeconomics', 'computer_security', 'moral_scenarios', 'moral_disputes', 'electrical_engineering', 'astronomy', 'college_biology']
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 22.50575356, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02031703, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02030943, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01997798, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02040213, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02030032, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01012292, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02029969, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02030243, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.00828325, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02031127, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02029852, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02031373, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02030226, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01998779, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02030358, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01851073, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02028377, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.00771859, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02029643, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.0202892, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02029737, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.00917781, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01334598, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.00498142, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.00633137, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01603949, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02027297, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.00964623, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01305331, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02029565, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.00575431, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01226125, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.00742112, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.0202789, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02028023, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02033279, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01861498, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01935337, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02029093, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02034042, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01755865, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02026897, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.00807692, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02030409, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01811336, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.00836539, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01889569, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.0089159, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02029515, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01800457, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02029242, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02032785, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02018568, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02026333, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02033358, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02041479, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02034433, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02029127, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.00637454, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02029277, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02030692, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01101249, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01782291, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02029989, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02030423, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02030244, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01928728, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02028524, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.00828915, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02030688, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.0177065, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02029841, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.0203129, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02030821, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02030356, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.00035685, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02032689, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02031026, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01662034, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02014084, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01787308, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02030818, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02030245, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02027592, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02030651, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02029266, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02030566, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02027942, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.00342127, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02028944, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.00260204, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02028129, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02029246, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02030049, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01658454, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02029051, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02027656, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.00822969, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02027756, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.0174781, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02030491, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.00241054, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02030537, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.00917241, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.0202836, 'samples/s': 0.0, 'tokens/s': 0.0}
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[WARNING:modelscope] Use trust_remote_code=True. Will invoke codes from modelscope/mmlu. Please make sure that you can trust the external codes.
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01939474, 'samples/s': 0.0, 'tokens/s': 0.0}
2025-05-12 16:34:08,534 - evalscope - INFO - Use settings: > few_shot_num: 5, > few_shot_split: train, > target_eval_split: test
Predicting(high_school_european_history):   0%|          | 0/5 [00:00<?, ?it/s]INFO:     127.0.0.1:50256 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_european_history):  20%|██        | 1/5 [00:10<00:40, 10.15s/it]INFO:     127.0.0.1:50268 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_european_history):  40%|████      | 2/5 [00:13<00:17,  5.93s/it]INFO:     127.0.0.1:50280 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_european_history):  60%|██████    | 3/5 [00:16<00:09,  4.69s/it][INFO:swift] {'num_prompt_tokens': 7215, 'num_generated_tokens': 9, 'num_samples': 3, 'runtime': 20.01555385, 'samples/s': 0.14988344, 'tokens/s': 0.44965031}
INFO:     127.0.0.1:50294 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_european_history):  80%|████████  | 4/5 [00:19<00:03,  3.95s/it][INFO:swift] {'num_prompt_tokens': 2270, 'num_generated_tokens': 3, 'num_samples': 1, 'runtime': 20.01979582, 'samples/s': 0.04995056, 'tokens/s': 0.14985168}
INFO:     127.0.0.1:50304 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_european_history): 100%|██████████| 5/5 [00:36<00:00,  8.90s/it]Predicting(high_school_european_history): 100%|██████████| 5/5 [00:36<00:00,  7.37s/it]
2025-05-12 16:34:46,999 - evalscope - INFO - Dump predictions to /home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline/native/20250512_155825/predictions/Qwen2.5-3B/mmlu_high_school_european_history.jsonl.
Reviewing(high_school_european_history):   0%|          | 0/5 [00:00<?, ?it/s]Reviewing(high_school_european_history):  60%|██████    | 3/5 [00:00<00:00, 28.19it/s]Reviewing(high_school_european_history): 100%|██████████| 5/5 [00:00<00:00, 27.92it/s]
Predicting(business_ethics):   0%|          | 0/5 [00:00<?, ?it/s]INFO:     127.0.0.1:50304 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(business_ethics):  20%|██        | 1/5 [00:00<00:03,  1.09it/s]INFO:     127.0.0.1:42698 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(business_ethics):  40%|████      | 2/5 [00:01<00:02,  1.21it/s]INFO:     127.0.0.1:42710 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(business_ethics):  60%|██████    | 3/5 [00:02<00:01,  1.16it/s]INFO:     127.0.0.1:42714 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(business_ethics):  80%|████████  | 4/5 [00:03<00:00,  1.23it/s]INFO:     127.0.0.1:42718 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(business_ethics): 100%|██████████| 5/5 [00:04<00:00,  1.22it/s]Predicting(business_ethics): 100%|██████████| 5/5 [00:04<00:00,  1.20it/s]
2025-05-12 16:34:51,340 - evalscope - INFO - Dump predictions to /home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline/native/20250512_155825/predictions/Qwen2.5-3B/mmlu_business_ethics.jsonl.
Reviewing(business_ethics):   0%|          | 0/5 [00:00<?, ?it/s]Reviewing(business_ethics):  40%|████      | 2/5 [00:00<00:00, 11.98it/s]Reviewing(business_ethics):  80%|████████  | 4/5 [00:00<00:00, 13.51it/s]Reviewing(business_ethics): 100%|██████████| 5/5 [00:00<00:00, 13.65it/s]
Predicting(clinical_knowledge):   0%|          | 0/5 [00:00<?, ?it/s][INFO:swift] {'num_prompt_tokens': 5223, 'num_generated_tokens': 319, 'num_samples': 6, 'runtime': 20.01956768, 'samples/s': 0.29970677, 'tokens/s': 15.93441003}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01964116, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01960643, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01962884, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:50304 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(clinical_knowledge):  20%|██        | 1/5 [01:24<05:38, 84.59s/it][INFO:swift] {'num_prompt_tokens': 379, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.01959103, 'samples/s': 0.04995107, 'tokens/s': 102.29979209}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02014158, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01931593, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.00463956, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:42710 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(clinical_knowledge):  40%|████      | 2/5 [02:49<04:13, 84.59s/it][INFO:swift] {'num_prompt_tokens': 391, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.01033572, 'samples/s': 0.04997417, 'tokens/s': 102.34710847}
INFO:     127.0.0.1:42698 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(clinical_knowledge):  60%|██████    | 3/5 [02:55<01:38, 49.03s/it]INFO:     127.0.0.1:42714 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(clinical_knowledge):  80%|████████  | 4/5 [03:13<00:36, 36.58s/it][INFO:swift] {'num_prompt_tokens': 800, 'num_generated_tokens': 602, 'num_samples': 2, 'runtime': 20.02010703, 'samples/s': 0.09989957, 'tokens/s': 30.06976932}
INFO:     127.0.0.1:42718 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(clinical_knowledge): 100%|██████████| 5/5 [03:33<00:00, 30.74s/it]Predicting(clinical_knowledge): 100%|██████████| 5/5 [03:33<00:00, 42.76s/it]
2025-05-12 16:38:25,490 - evalscope - INFO - Dump predictions to /home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline/native/20250512_155825/predictions/Qwen2.5-3B/mmlu_clinical_knowledge.jsonl.
Reviewing(clinical_knowledge):   0%|          | 0/5 [00:00<?, ?it/s]Reviewing(clinical_knowledge): 100%|██████████| 5/5 [00:00<00:00, 166.06it/s]
Predicting(medical_genetics):   0%|          | 0/5 [00:00<?, ?it/s][INFO:swift] {'num_prompt_tokens': 406, 'num_generated_tokens': 516, 'num_samples': 1, 'runtime': 20.01992469, 'samples/s': 0.04995024, 'tokens/s': 25.77432272}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02014078, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.0201152, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:42718 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(medical_genetics):  20%|██        | 1/5 [00:55<03:40, 55.14s/it]INFO:     127.0.0.1:48848 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(medical_genetics):  40%|████      | 2/5 [00:58<01:14, 24.80s/it][INFO:swift] {'num_prompt_tokens': 705, 'num_generated_tokens': 1482, 'num_samples': 2, 'runtime': 20.01742477, 'samples/s': 0.09991295, 'tokens/s': 74.03549743}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01341479, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01956244, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01979603, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.00097475, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:48856 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(medical_genetics):  60%|██████    | 3/5 [02:22<01:43, 51.85s/it][INFO:swift] {'num_prompt_tokens': 324, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.01870351, 'samples/s': 0.04995328, 'tokens/s': 102.30432748}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01952737, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01985336, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02011951, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:48872 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(medical_genetics):  80%|████████  | 4/5 [03:46<01:04, 64.60s/it]INFO:     127.0.0.1:48888 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(medical_genetics): 100%|██████████| 5/5 [03:51<00:00, 43.11s/it]Predicting(medical_genetics): 100%|██████████| 5/5 [03:51<00:00, 46.38s/it]
2025-05-12 16:42:17,416 - evalscope - INFO - Dump predictions to /home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline/native/20250512_155825/predictions/Qwen2.5-3B/mmlu_medical_genetics.jsonl.
Reviewing(medical_genetics):   0%|          | 0/5 [00:00<?, ?it/s]Reviewing(medical_genetics): 100%|██████████| 5/5 [00:00<00:00, 132.78it/s]
Predicting(high_school_us_history):   0%|          | 0/5 [00:00<?, ?it/s][INFO:swift] {'num_prompt_tokens': 700, 'num_generated_tokens': 2167, 'num_samples': 2, 'runtime': 20.01572504, 'samples/s': 0.09992144, 'tokens/s': 108.26487655}
INFO:     127.0.0.1:48888 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_us_history):  20%|██        | 1/5 [00:10<00:41, 10.44s/it]INFO:     127.0.0.1:53314 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_us_history):  40%|████      | 2/5 [00:12<00:16,  5.53s/it]INFO:     127.0.0.1:53332 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_us_history):  60%|██████    | 3/5 [00:26<00:18,  9.31s/it][INFO:swift] {'num_prompt_tokens': 5766, 'num_generated_tokens': 442, 'num_samples': 3, 'runtime': 20.0194612, 'samples/s': 0.14985418, 'tokens/s': 22.07851628}
INFO:     127.0.0.1:53318 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_us_history):  80%|████████  | 4/5 [00:39<00:10, 10.83s/it]INFO:     127.0.0.1:53336 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_us_history): 100%|██████████| 5/5 [00:41<00:00,  7.76s/it]Predicting(high_school_us_history): 100%|██████████| 5/5 [00:41<00:00,  8.36s/it]
2025-05-12 16:42:59,282 - evalscope - INFO - Dump predictions to /home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline/native/20250512_155825/predictions/Qwen2.5-3B/mmlu_high_school_us_history.jsonl.
Reviewing(high_school_us_history):   0%|          | 0/5 [00:00<?, ?it/s]Reviewing(high_school_us_history):  60%|██████    | 3/5 [00:00<00:00, 27.04it/s]Reviewing(high_school_us_history): 100%|██████████| 5/5 [00:00<00:00, 18.86it/s]
Predicting(high_school_physics):   0%|          | 0/5 [00:00<?, ?it/s][INFO:swift] {'num_prompt_tokens': 3942, 'num_generated_tokens': 245, 'num_samples': 2, 'runtime': 20.02010074, 'samples/s': 0.0998996, 'tokens/s': 12.23770066}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01635959, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02014522, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01869306, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:53336 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_physics):  20%|██        | 1/5 [01:26<05:47, 86.91s/it][INFO:swift] {'num_prompt_tokens': 588, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.02010679, 'samples/s': 0.04994978, 'tokens/s': 102.29715663}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.00707546, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.00643311, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02016537, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01705459, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:53318 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_physics):  40%|████      | 2/5 [02:53<04:19, 86.57s/it][INFO:swift] {'num_prompt_tokens': 545, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.01439275, 'samples/s': 0.04996404, 'tokens/s': 102.32636209}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01722617, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.0198993, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02011401, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:51024 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_physics):  60%|██████    | 3/5 [04:20<02:53, 86.82s/it][INFO:swift] {'num_prompt_tokens': 624, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.00303808, 'samples/s': 0.04999241, 'tokens/s': 102.3844474}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02009274, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01977271, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.00150153, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:51038 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_physics):  80%|████████  | 4/5 [05:46<01:26, 86.61s/it][INFO:swift] {'num_prompt_tokens': 548, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.01797571, 'samples/s': 0.0499551, 'tokens/s': 102.30804703}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01985073, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.0201055, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01961516, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02011445, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:51042 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_physics): 100%|██████████| 5/5 [07:14<00:00, 86.96s/it]Predicting(high_school_physics): 100%|██████████| 5/5 [07:14<00:00, 86.85s/it]
2025-05-12 16:50:13,789 - evalscope - INFO - Dump predictions to /home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline/native/20250512_155825/predictions/Qwen2.5-3B/mmlu_high_school_physics.jsonl.
Reviewing(high_school_physics):   0%|          | 0/5 [00:00<?, ?it/s]Reviewing(high_school_physics):  40%|████      | 2/5 [00:00<00:00, 12.98it/s]Reviewing(high_school_physics):  80%|████████  | 4/5 [00:00<00:00,  9.32it/s]Reviewing(high_school_physics): 100%|██████████| 5/5 [00:00<00:00,  8.96it/s]Reviewing(high_school_physics): 100%|██████████| 5/5 [00:00<00:00,  9.38it/s]
Predicting(high_school_world_history):   0%|          | 0/5 [00:00<?, ?it/s]INFO:     127.0.0.1:51042 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_world_history):  20%|██        | 1/5 [00:08<00:35,  8.87s/it][INFO:swift] {'num_prompt_tokens': 1918, 'num_generated_tokens': 2237, 'num_samples': 2, 'runtime': 20.0201, 'samples/s': 0.0998996, 'tokens/s': 111.7377036}
INFO:     127.0.0.1:60352 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_world_history):  40%|████      | 2/5 [00:20<00:31, 10.45s/it][INFO:swift] {'num_prompt_tokens': 1515, 'num_generated_tokens': 239, 'num_samples': 1, 'runtime': 20.01906181, 'samples/s': 0.04995239, 'tokens/s': 11.93862141}
INFO:     127.0.0.1:60368 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_world_history):  60%|██████    | 3/5 [00:34<00:23, 11.92s/it]INFO:     127.0.0.1:60378 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_world_history):  80%|████████  | 4/5 [00:50<00:13, 13.75s/it][INFO:swift] {'num_prompt_tokens': 2501, 'num_generated_tokens': 695, 'num_samples': 2, 'runtime': 20.01979882, 'samples/s': 0.0999011, 'tokens/s': 34.71563357}
INFO:     127.0.0.1:60384 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_world_history): 100%|██████████| 5/5 [01:00<00:00, 12.20s/it]Predicting(high_school_world_history): 100%|██████████| 5/5 [01:00<00:00, 12.02s/it]
2025-05-12 16:51:14,445 - evalscope - INFO - Dump predictions to /home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline/native/20250512_155825/predictions/Qwen2.5-3B/mmlu_high_school_world_history.jsonl.
Reviewing(high_school_world_history):   0%|          | 0/5 [00:00<?, ?it/s]Reviewing(high_school_world_history):  20%|██        | 1/5 [00:00<00:00,  9.75it/s]Reviewing(high_school_world_history):  60%|██████    | 3/5 [00:00<00:00, 10.33it/s]Reviewing(high_school_world_history): 100%|██████████| 5/5 [00:00<00:00,  8.61it/s]Reviewing(high_school_world_history): 100%|██████████| 5/5 [00:00<00:00,  8.91it/s]
Predicting(virology):   0%|          | 0/5 [00:00<?, ?it/s][INFO:swift] {'num_prompt_tokens': 1340, 'num_generated_tokens': 199, 'num_samples': 1, 'runtime': 20.01988067, 'samples/s': 0.04995035, 'tokens/s': 9.94011919}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02011115, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02009733, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01902981, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:60384 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(virology):  20%|██        | 1/5 [01:24<05:36, 84.15s/it][INFO:swift] {'num_prompt_tokens': 336, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.02015473, 'samples/s': 0.04994966, 'tokens/s': 102.29691169}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01947168, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.0197039, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02009359, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:44586 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(virology):  40%|████      | 2/5 [02:48<04:12, 84.03s/it][INFO:swift] {'num_prompt_tokens': 321, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.01958584, 'samples/s': 0.04995108, 'tokens/s': 102.29981862}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01984809, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01964889, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01973883, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:44602 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(virology):  60%|██████    | 3/5 [04:12<02:48, 84.11s/it][INFO:swift] {'num_prompt_tokens': 344, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.02009232, 'samples/s': 0.04994982, 'tokens/s': 102.29723059}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01964545, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02011371, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.00330246, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.0201079, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:44604 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(virology):  80%|████████  | 4/5 [05:36<01:24, 84.18s/it]INFO:     127.0.0.1:44612 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(virology): 100%|██████████| 5/5 [05:45<00:00, 57.02s/it]Predicting(virology): 100%|██████████| 5/5 [05:45<00:00, 69.09s/it]
2025-05-12 16:57:00,456 - evalscope - INFO - Dump predictions to /home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline/native/20250512_155825/predictions/Qwen2.5-3B/mmlu_virology.jsonl.
Reviewing(virology):   0%|          | 0/5 [00:00<?, ?it/s]Reviewing(virology): 100%|██████████| 5/5 [00:00<00:00, 97.10it/s]
Predicting(high_school_microeconomics):   0%|          | 0/5 [00:00<?, ?it/s][INFO:swift] {'num_prompt_tokens': 674, 'num_generated_tokens': 2256, 'num_samples': 2, 'runtime': 20.01958282, 'samples/s': 0.09990218, 'tokens/s': 112.68966092}
INFO:     127.0.0.1:44612 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_microeconomics):  20%|██        | 1/5 [00:11<00:46, 11.55s/it][INFO:swift] {'num_prompt_tokens': 438, 'num_generated_tokens': 287, 'num_samples': 1, 'runtime': 20.0198604, 'samples/s': 0.0499504, 'tokens/s': 14.3357643}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02011877, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.00558195, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01755477, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:51610 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_microeconomics):  40%|████      | 2/5 [01:37<02:45, 55.07s/it]INFO:     127.0.0.1:51620 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_microeconomics):  60%|██████    | 3/5 [01:41<01:04, 32.15s/it][INFO:swift] {'num_prompt_tokens': 719, 'num_generated_tokens': 2164, 'num_samples': 2, 'runtime': 20.01988487, 'samples/s': 0.09990067, 'tokens/s': 108.0925297}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02013838, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.00332915, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.00401087, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:51628 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_microeconomics):  80%|████████  | 4/5 [03:06<00:52, 52.92s/it][INFO:swift] {'num_prompt_tokens': 350, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.01961989, 'samples/s': 0.049951, 'tokens/s': 102.2996446}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01978263, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01957163, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01497651, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02013974, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:51638 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_microeconomics): 100%|██████████| 5/5 [04:35<00:00, 65.82s/it]Predicting(high_school_microeconomics): 100%|██████████| 5/5 [04:35<00:00, 55.08s/it]
2025-05-12 17:01:35,932 - evalscope - INFO - Dump predictions to /home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline/native/20250512_155825/predictions/Qwen2.5-3B/mmlu_high_school_microeconomics.jsonl.
Reviewing(high_school_microeconomics):   0%|          | 0/5 [00:00<?, ?it/s]Reviewing(high_school_microeconomics): 100%|██████████| 5/5 [00:00<00:00, 180.84it/s]
Predicting(econometrics):   0%|          | 0/5 [00:00<?, ?it/s][INFO:swift] {'num_prompt_tokens': 382, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.01134468, 'samples/s': 0.04997165, 'tokens/s': 102.34194816}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01670726, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01250733, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01893729, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:51638 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(econometrics):  20%|██        | 1/5 [01:28<05:55, 88.77s/it][INFO:swift] {'num_prompt_tokens': 651, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.01988698, 'samples/s': 0.04995033, 'tokens/s': 102.29827983}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02016439, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02020331, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01879745, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01631026, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:39702 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(econometrics):  40%|████      | 2/5 [03:00<04:31, 90.49s/it]INFO:     127.0.0.1:39710 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(econometrics):  60%|██████    | 3/5 [03:10<01:47, 53.65s/it][INFO:swift] {'num_prompt_tokens': 1273, 'num_generated_tokens': 2265, 'num_samples': 2, 'runtime': 20.01937956, 'samples/s': 0.0999032, 'tokens/s': 113.14036947}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01980424, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02020211, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02013841, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02013396, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:39724 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(econometrics):  80%|████████  | 4/5 [04:41<01:08, 68.43s/it][INFO:swift] {'num_prompt_tokens': 614, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.02017085, 'samples/s': 0.04994962, 'tokens/s': 102.29682933}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02020949, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01763885, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02013756, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01954749, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:39728 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(econometrics): 100%|██████████| 5/5 [06:14<00:00, 77.29s/it]Predicting(econometrics): 100%|██████████| 5/5 [06:14<00:00, 74.87s/it]
2025-05-12 17:07:50,330 - evalscope - INFO - Dump predictions to /home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline/native/20250512_155825/predictions/Qwen2.5-3B/mmlu_econometrics.jsonl.
Reviewing(econometrics):   0%|          | 0/5 [00:00<?, ?it/s]Reviewing(econometrics):  80%|████████  | 4/5 [00:00<00:00, 30.37it/s]Reviewing(econometrics): 100%|██████████| 5/5 [00:00<00:00, 31.18it/s]
Predicting(college_computer_science):   0%|          | 0/5 [00:00<?, ?it/s][INFO:swift] {'num_prompt_tokens': 653, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.01978838, 'samples/s': 0.04995058, 'tokens/s': 102.29878366}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01963069, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.0197564, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.0198243, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:39728 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(college_computer_science):  20%|██        | 1/5 [01:35<06:23, 95.83s/it][INFO:swift] {'num_prompt_tokens': 838, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.01987169, 'samples/s': 0.04995037, 'tokens/s': 102.29835795}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01980614, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01960549, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01982275, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02014539, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:49502 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(college_computer_science):  40%|████      | 2/5 [03:11<04:47, 95.98s/it][INFO:swift] {'num_prompt_tokens': 882, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.01947347, 'samples/s': 0.04995136, 'tokens/s': 102.30039282}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.00432468, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.0192584, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:49510 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(college_computer_science):  60%|██████    | 3/5 [04:01<02:29, 74.99s/it]INFO:     127.0.0.1:49508 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(college_computer_science):  80%|████████  | 4/5 [04:09<00:48, 48.31s/it][INFO:swift] {'num_prompt_tokens': 1660, 'num_generated_tokens': 1263, 'num_samples': 2, 'runtime': 20.01978098, 'samples/s': 0.09990119, 'tokens/s': 63.08760327}
INFO:     127.0.0.1:49518 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(college_computer_science): 100%|██████████| 5/5 [04:25<00:00, 36.80s/it]Predicting(college_computer_science): 100%|██████████| 5/5 [04:25<00:00, 53.14s/it]
2025-05-12 17:12:16,218 - evalscope - INFO - Dump predictions to /home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline/native/20250512_155825/predictions/Qwen2.5-3B/mmlu_college_computer_science.jsonl.
Reviewing(college_computer_science):   0%|          | 0/5 [00:00<?, ?it/s]Reviewing(college_computer_science): 100%|██████████| 5/5 [00:00<00:00, 158.05it/s]
Predicting(high_school_biology):   0%|          | 0/5 [00:00<?, ?it/s][INFO:swift] {'num_prompt_tokens': 808, 'num_generated_tokens': 346, 'num_samples': 1, 'runtime': 20.0199034, 'samples/s': 0.04995029, 'tokens/s': 17.28280068}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01966065, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.00143052, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01794017, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01985963, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:49518 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_biology):  20%|██        | 1/5 [01:33<06:14, 93.52s/it]INFO:     127.0.0.1:55564 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_biology):  40%|████      | 2/5 [01:43<02:13, 44.50s/it][INFO:swift] {'num_prompt_tokens': 1011, 'num_generated_tokens': 2268, 'num_samples': 2, 'runtime': 20.01980359, 'samples/s': 0.09990108, 'tokens/s': 113.2878247}
INFO:     127.0.0.1:55566 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_biology):  60%|██████    | 3/5 [01:57<01:00, 30.38s/it]INFO:     127.0.0.1:55574 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_biology):  80%|████████  | 4/5 [02:07<00:22, 22.57s/it][INFO:swift] {'num_prompt_tokens': 1009, 'num_generated_tokens': 526, 'num_samples': 2, 'runtime': 20.01957649, 'samples/s': 0.09990221, 'tokens/s': 26.27428209}
INFO:     127.0.0.1:55586 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_biology): 100%|██████████| 5/5 [02:14<00:00, 16.75s/it]Predicting(high_school_biology): 100%|██████████| 5/5 [02:14<00:00, 26.86s/it]
2025-05-12 17:14:30,576 - evalscope - INFO - Dump predictions to /home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline/native/20250512_155825/predictions/Qwen2.5-3B/mmlu_high_school_biology.jsonl.
Reviewing(high_school_biology):   0%|          | 0/5 [00:00<?, ?it/s]Reviewing(high_school_biology):  40%|████      | 2/5 [00:00<00:00, 19.21it/s]Reviewing(high_school_biology):  80%|████████  | 4/5 [00:00<00:00, 18.61it/s]Reviewing(high_school_biology): 100%|██████████| 5/5 [00:00<00:00, 16.33it/s]
Predicting(abstract_algebra):   0%|          | 0/5 [00:00<?, ?it/s][INFO:swift] {'num_prompt_tokens': 502, 'num_generated_tokens': 133, 'num_samples': 1, 'runtime': 20.01983408, 'samples/s': 0.04995046, 'tokens/s': 6.6434117}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.0201383, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01962592, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01972328, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:55586 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(abstract_algebra):  20%|██        | 1/5 [01:32<06:08, 92.03s/it][INFO:swift] {'num_prompt_tokens': 373, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.01956409, 'samples/s': 0.04995114, 'tokens/s': 102.29992973}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01981708, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01982122, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01990028, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01953422, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:50660 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(abstract_algebra):  40%|████      | 2/5 [03:07<04:42, 94.29s/it][INFO:swift] {'num_prompt_tokens': 377, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.02016307, 'samples/s': 0.04994964, 'tokens/s': 102.29686905}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01539183, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01984592, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01970755, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02013402, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:50674 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(abstract_algebra):  60%|██████    | 3/5 [04:43<03:09, 94.70s/it][INFO:swift] {'num_prompt_tokens': 387, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.01914312, 'samples/s': 0.04995219, 'tokens/s': 102.30208096}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.00128818, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.0184434, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02018085, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:50676 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(abstract_algebra):  80%|████████  | 4/5 [06:17<01:34, 94.78s/it][INFO:swift] {'num_prompt_tokens': 400, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.01901188, 'samples/s': 0.04995252, 'tokens/s': 102.30275161}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01985301, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01989795, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01966194, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01960237, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:50680 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(abstract_algebra): 100%|██████████| 5/5 [07:53<00:00, 95.21s/it]Predicting(abstract_algebra): 100%|██████████| 5/5 [07:53<00:00, 94.79s/it]
2025-05-12 17:22:24,865 - evalscope - INFO - Dump predictions to /home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline/native/20250512_155825/predictions/Qwen2.5-3B/mmlu_abstract_algebra.jsonl.
Reviewing(abstract_algebra):   0%|          | 0/5 [00:00<?, ?it/s]Reviewing(abstract_algebra): 100%|██████████| 5/5 [00:00<00:00, 46.18it/s]Reviewing(abstract_algebra): 100%|██████████| 5/5 [00:00<00:00, 45.96it/s]
Predicting(professional_accounting):   0%|          | 0/5 [00:00<?, ?it/s]INFO:     127.0.0.1:50680 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(professional_accounting):  20%|██        | 1/5 [00:01<00:06,  1.51s/it][INFO:swift] {'num_prompt_tokens': 1043, 'num_generated_tokens': 2064, 'num_samples': 2, 'runtime': 20.01977747, 'samples/s': 0.09990121, 'tokens/s': 103.09804907}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01979872, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01977343, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01959243, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01971289, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:44478 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(professional_accounting):  40%|████      | 2/5 [01:37<02:50, 56.99s/it][INFO:swift] {'num_prompt_tokens': 636, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.01982098, 'samples/s': 0.0499505, 'tokens/s': 102.29861705}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.00414537, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01939313, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01965329, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02015185, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:44494 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(professional_accounting):  60%|██████    | 3/5 [03:13<02:29, 74.97s/it][INFO:swift] {'num_prompt_tokens': 598, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.01948615, 'samples/s': 0.04995133, 'tokens/s': 102.30032804}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01984758, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01952411, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01976132, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01976805, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:44508 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(professional_accounting):  80%|████████  | 4/5 [04:50<01:23, 83.64s/it]INFO:     127.0.0.1:44510 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(professional_accounting): 100%|██████████| 5/5 [05:02<00:00, 57.62s/it]Predicting(professional_accounting): 100%|██████████| 5/5 [05:02<00:00, 60.42s/it]
2025-05-12 17:27:27,105 - evalscope - INFO - Dump predictions to /home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline/native/20250512_155825/predictions/Qwen2.5-3B/mmlu_professional_accounting.jsonl.
Reviewing(professional_accounting):   0%|          | 0/5 [00:00<?, ?it/s]Reviewing(professional_accounting):  60%|██████    | 3/5 [00:00<00:00, 20.57it/s]Reviewing(professional_accounting): 100%|██████████| 5/5 [00:00<00:00, 18.98it/s]
Predicting(philosophy):   0%|          | 0/5 [00:00<?, ?it/s]INFO:     127.0.0.1:44510 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(philosophy):  20%|██        | 1/5 [00:01<00:05,  1.47s/it][INFO:swift] {'num_prompt_tokens': 1589, 'num_generated_tokens': 2308, 'num_samples': 3, 'runtime': 20.01984292, 'samples/s': 0.14985133, 'tokens/s': 115.28561983}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01300132, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01843773, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01966526, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01984746, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:39656 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(philosophy):  40%|████      | 2/5 [01:37<02:50, 56.85s/it][INFO:swift] {'num_prompt_tokens': 599, 'num_generated_tokens': 2154, 'num_samples': 2, 'runtime': 20.01999605, 'samples/s': 0.09990012, 'tokens/s': 107.59242884}
INFO:     127.0.0.1:39662 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(philosophy):  60%|██████    | 3/5 [01:42<01:06, 33.32s/it][INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01966025, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02014688, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02015135, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01899594, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:39674 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(philosophy):  80%|████████  | 4/5 [03:18<00:58, 58.02s/it][INFO:swift] {'num_prompt_tokens': 335, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.02016287, 'samples/s': 0.04994964, 'tokens/s': 102.29687005}
INFO:     127.0.0.1:39690 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(philosophy): 100%|██████████| 5/5 [03:33<00:00, 42.51s/it]Predicting(philosophy): 100%|██████████| 5/5 [03:33<00:00, 42.66s/it]
2025-05-12 17:31:00,688 - evalscope - INFO - Dump predictions to /home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline/native/20250512_155825/predictions/Qwen2.5-3B/mmlu_philosophy.jsonl.
Reviewing(philosophy):   0%|          | 0/5 [00:00<?, ?it/s]Reviewing(philosophy):  20%|██        | 1/5 [00:00<00:00,  9.50it/s]Reviewing(philosophy):  40%|████      | 2/5 [00:00<00:00,  9.22it/s]Reviewing(philosophy):  60%|██████    | 3/5 [00:00<00:00,  8.35it/s]Reviewing(philosophy):  80%|████████  | 4/5 [00:00<00:00,  8.33it/s]Reviewing(philosophy): 100%|██████████| 5/5 [00:00<00:00,  8.07it/s]Reviewing(philosophy): 100%|██████████| 5/5 [00:00<00:00,  8.32it/s]
Predicting(professional_medicine):   0%|          | 0/5 [00:00<?, ?it/s]INFO:     127.0.0.1:53774 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(professional_medicine):  20%|██        | 1/5 [00:03<00:12,  3.05s/it]INFO:     127.0.0.1:39690 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(professional_medicine):  40%|████      | 2/5 [00:05<00:08,  2.94s/it][INFO:swift] {'num_prompt_tokens': 2118, 'num_generated_tokens': 417, 'num_samples': 3, 'runtime': 20.01948592, 'samples/s': 0.149854, 'tokens/s': 20.8297057}
INFO:     127.0.0.1:53790 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(professional_medicine):  60%|██████    | 3/5 [00:08<00:05,  2.86s/it]INFO:     127.0.0.1:53760 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(professional_medicine):  80%|████████  | 4/5 [00:11<00:03,  3.00s/it]INFO:     127.0.0.1:53804 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(professional_medicine): 100%|██████████| 5/5 [00:23<00:00,  6.08s/it]Predicting(professional_medicine): 100%|██████████| 5/5 [00:23<00:00,  4.69s/it]
2025-05-12 17:31:24,746 - evalscope - INFO - Dump predictions to /home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline/native/20250512_155825/predictions/Qwen2.5-3B/mmlu_professional_medicine.jsonl.
Reviewing(professional_medicine):   0%|          | 0/5 [00:00<?, ?it/s]Reviewing(professional_medicine):  60%|██████    | 3/5 [00:00<00:00, 28.47it/s]Reviewing(professional_medicine): 100%|██████████| 5/5 [00:00<00:00, 28.20it/s]
Predicting(nutrition):   0%|          | 0/5 [00:00<?, ?it/s][INFO:swift] {'num_prompt_tokens': 2587, 'num_generated_tokens': 329, 'num_samples': 3, 'runtime': 20.01976285, 'samples/s': 0.14985192, 'tokens/s': 16.4337611}
INFO:     127.0.0.1:53804 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(nutrition):  20%|██        | 1/5 [00:14<00:58, 14.65s/it]INFO:     127.0.0.1:42910 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(nutrition):  40%|████      | 2/5 [00:23<00:34, 11.46s/it][INFO:swift] {'num_prompt_tokens': 1051, 'num_generated_tokens': 495, 'num_samples': 2, 'runtime': 20.02014444, 'samples/s': 0.09989938, 'tokens/s': 24.72509634}
INFO:     127.0.0.1:42920 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(nutrition):  60%|██████    | 3/5 [00:37<00:25, 12.55s/it]INFO:     127.0.0.1:42922 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(nutrition):  80%|████████  | 4/5 [00:40<00:08,  8.54s/it]INFO:     127.0.0.1:42926 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(nutrition): 100%|██████████| 5/5 [00:42<00:00,  6.28s/it]Predicting(nutrition): 100%|██████████| 5/5 [00:42<00:00,  8.48s/it]
2025-05-12 17:32:07,337 - evalscope - INFO - Dump predictions to /home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline/native/20250512_155825/predictions/Qwen2.5-3B/mmlu_nutrition.jsonl.
Reviewing(nutrition):   0%|          | 0/5 [00:00<?, ?it/s]Reviewing(nutrition):  40%|████      | 2/5 [00:00<00:00, 18.55it/s]Reviewing(nutrition): 100%|██████████| 5/5 [00:00<00:00, 19.95it/s]Reviewing(nutrition): 100%|██████████| 5/5 [00:00<00:00, 19.73it/s]
Predicting(global_facts):   0%|          | 0/5 [00:00<?, ?it/s][INFO:swift] {'num_prompt_tokens': 1476, 'num_generated_tokens': 376, 'num_samples': 3, 'runtime': 20.02020292, 'samples/s': 0.14984863, 'tokens/s': 18.78102842}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02019892, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:42922 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(global_facts):  20%|██        | 1/5 [00:27<01:50, 27.57s/it]INFO:     127.0.0.1:41112 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(global_facts):  40%|████      | 2/5 [00:31<00:41, 13.70s/it][INFO:swift] {'num_prompt_tokens': 708, 'num_generated_tokens': 671, 'num_samples': 2, 'runtime': 20.01680144, 'samples/s': 0.09991606, 'tokens/s': 33.52183924}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.0176295, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01982928, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01983945, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01960246, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:42926 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(global_facts):  60%|██████    | 3/5 [02:03<01:39, 49.54s/it]INFO:     127.0.0.1:41120 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(global_facts):  80%|████████  | 4/5 [02:12<00:33, 33.49s/it][INFO:swift] {'num_prompt_tokens': 724, 'num_generated_tokens': 2242, 'num_samples': 2, 'runtime': 20.01979795, 'samples/s': 0.09990111, 'tokens/s': 111.98914225}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01977815, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01987686, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:41132 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(global_facts): 100%|██████████| 5/5 [03:13<00:00, 43.26s/it]Predicting(global_facts): 100%|██████████| 5/5 [03:13<00:00, 38.64s/it]
2025-05-12 17:35:20,852 - evalscope - INFO - Dump predictions to /home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline/native/20250512_155825/predictions/Qwen2.5-3B/mmlu_global_facts.jsonl.
Reviewing(global_facts):   0%|          | 0/5 [00:00<?, ?it/s]Reviewing(global_facts): 100%|██████████| 5/5 [00:00<00:00, 134.99it/s]
Predicting(machine_learning):   0%|          | 0/5 [00:00<?, ?it/s][INFO:swift] {'num_prompt_tokens': 354, 'num_generated_tokens': 1368, 'num_samples': 1, 'runtime': 20.01971077, 'samples/s': 0.04995077, 'tokens/s': 68.33265552}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02015509, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02016756, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01902511, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01986922, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:41132 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(machine_learning):  20%|██        | 1/5 [01:33<06:14, 93.70s/it][INFO:swift] {'num_prompt_tokens': 597, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.01943936, 'samples/s': 0.04995145, 'tokens/s': 102.30056714}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02014783, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01063142, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01669275, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:39542 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(machine_learning):  40%|████      | 2/5 [03:07<04:40, 93.53s/it][INFO:swift] {'num_prompt_tokens': 602, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.01970641, 'samples/s': 0.04995078, 'tokens/s': 102.29920248}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01970691, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.00719366, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02017806, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01318409, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:39550 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(machine_learning):  60%|██████    | 3/5 [04:40<03:07, 93.50s/it][INFO:swift] {'num_prompt_tokens': 594, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.02018868, 'samples/s': 0.04994958, 'tokens/s': 102.29673818}
INFO:     127.0.0.1:39558 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(machine_learning):  80%|████████  | 4/5 [05:00<01:04, 64.27s/it][INFO:swift] {'num_prompt_tokens': 565, 'num_generated_tokens': 431, 'num_samples': 1, 'runtime': 20.0202076, 'samples/s': 0.04994953, 'tokens/s': 21.52824829}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02014166, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:39560 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(machine_learning): 100%|██████████| 5/5 [05:46<00:00, 57.76s/it]Predicting(machine_learning): 100%|██████████| 5/5 [05:46<00:00, 69.25s/it]
2025-05-12 17:41:07,159 - evalscope - INFO - Dump predictions to /home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline/native/20250512_155825/predictions/Qwen2.5-3B/mmlu_machine_learning.jsonl.
Reviewing(machine_learning):   0%|          | 0/5 [00:00<?, ?it/s]Reviewing(machine_learning):  60%|██████    | 3/5 [00:00<00:00, 24.18it/s]Reviewing(machine_learning): 100%|██████████| 5/5 [00:00<00:00, 24.96it/s]
Predicting(security_studies):   0%|          | 0/5 [00:00<?, ?it/s][INFO:swift] {'num_prompt_tokens': 601, 'num_generated_tokens': 1037, 'num_samples': 1, 'runtime': 20.02020062, 'samples/s': 0.04994955, 'tokens/s': 51.79768273}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01699296, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01964352, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01987807, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01974235, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:39560 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(security_studies):  20%|██        | 1/5 [01:35<06:22, 95.55s/it][INFO:swift] {'num_prompt_tokens': 933, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.01986943, 'samples/s': 0.04995038, 'tokens/s': 102.29836947}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.00689061, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02013168, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.0201191, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01996817, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:39230 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(security_studies):  40%|████      | 2/5 [03:11<04:47, 95.72s/it][INFO:swift] {'num_prompt_tokens': 1032, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.00370838, 'samples/s': 0.04999073, 'tokens/s': 102.38101662}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02014322, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.0160329, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01893443, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02015461, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:39234 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(security_studies):  60%|██████    | 3/5 [04:44<03:09, 94.63s/it][INFO:swift] {'num_prompt_tokens': 836, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.0192821, 'samples/s': 0.04995184, 'tokens/s': 102.30137071}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01976176, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01984463, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01989013, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:39248 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(security_studies):  80%|████████  | 4/5 [06:21<01:35, 95.38s/it][INFO:swift] {'num_prompt_tokens': 1087, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.01972315, 'samples/s': 0.04995074, 'tokens/s': 102.29911697}
INFO:     127.0.0.1:39260 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(security_studies): 100%|██████████| 5/5 [06:26<00:00, 62.93s/it]Predicting(security_studies): 100%|██████████| 5/5 [06:26<00:00, 77.33s/it]
2025-05-12 17:47:34,007 - evalscope - INFO - Dump predictions to /home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline/native/20250512_155825/predictions/Qwen2.5-3B/mmlu_security_studies.jsonl.
Reviewing(security_studies):   0%|          | 0/5 [00:00<?, ?it/s]Reviewing(security_studies):  80%|████████  | 4/5 [00:00<00:00, 28.71it/s]Reviewing(security_studies): 100%|██████████| 5/5 [00:00<00:00, 25.89it/s]
Predicting(public_relations):   0%|          | 0/5 [00:00<?, ?it/s]INFO:     127.0.0.1:39260 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(public_relations):  20%|██        | 1/5 [00:10<00:41, 10.27s/it][INFO:swift] {'num_prompt_tokens': 1465, 'num_generated_tokens': 330, 'num_samples': 2, 'runtime': 20.01971875, 'samples/s': 0.0999015, 'tokens/s': 16.48374805}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02015531, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01949531, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.00381397, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01974305, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:53216 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(public_relations):  40%|████      | 2/5 [01:39<02:50, 56.75s/it]INFO:     127.0.0.1:53226 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(public_relations):  60%|██████    | 3/5 [01:40<01:02, 31.15s/it]INFO:     127.0.0.1:53242 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(public_relations):  80%|████████  | 4/5 [01:49<00:22, 22.64s/it]INFO:     127.0.0.1:53252 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(public_relations): 100%|██████████| 5/5 [01:51<00:00, 14.97s/it]Predicting(public_relations): 100%|██████████| 5/5 [01:51<00:00, 22.24s/it]
2025-05-12 17:49:25,404 - evalscope - INFO - Dump predictions to /home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline/native/20250512_155825/predictions/Qwen2.5-3B/mmlu_public_relations.jsonl.
Reviewing(public_relations):   0%|          | 0/5 [00:00<?, ?it/s]Reviewing(public_relations): 100%|██████████| 5/5 [00:00<00:00, 342.81it/s]
Predicting(professional_psychology):   0%|          | 0/5 [00:00<?, ?it/s]INFO:     127.0.0.1:53242 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(professional_psychology):  20%|██        | 1/5 [00:02<00:09,  2.34s/it][INFO:swift] {'num_prompt_tokens': 1831, 'num_generated_tokens': 2338, 'num_samples': 5, 'runtime': 20.01970326, 'samples/s': 0.24975395, 'tokens/s': 116.78494778}
INFO:     127.0.0.1:53252 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(professional_psychology):  40%|████      | 2/5 [00:17<00:29,  9.82s/it]INFO:     127.0.0.1:49098 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(professional_psychology):  60%|██████    | 3/5 [00:19<00:12,  6.24s/it]INFO:     127.0.0.1:49092 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(professional_psychology):  80%|████████  | 4/5 [00:20<00:04,  4.05s/it]INFO:     127.0.0.1:49106 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(professional_psychology): 100%|██████████| 5/5 [00:22<00:00,  3.31s/it]Predicting(professional_psychology): 100%|██████████| 5/5 [00:22<00:00,  4.41s/it]
2025-05-12 17:49:47,491 - evalscope - INFO - Dump predictions to /home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline/native/20250512_155825/predictions/Qwen2.5-3B/mmlu_professional_psychology.jsonl.
Reviewing(professional_psychology):   0%|          | 0/5 [00:00<?, ?it/s]Reviewing(professional_psychology): 100%|██████████| 5/5 [00:00<00:00, 57.12it/s]
Predicting(prehistory):   0%|          | 0/5 [00:00<?, ?it/s][INFO:swift] {'num_prompt_tokens': 1759, 'num_generated_tokens': 419, 'num_samples': 4, 'runtime': 20.02015004, 'samples/s': 0.1997987, 'tokens/s': 20.92891407}
INFO:     127.0.0.1:53252 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(prehistory):  20%|██        | 1/5 [00:05<00:23,  5.93s/it]INFO:     127.0.0.1:49098 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(prehistory):  40%|████      | 2/5 [00:08<00:11,  3.78s/it]INFO:     127.0.0.1:49092 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(prehistory):  60%|██████    | 3/5 [00:21<00:16,  8.13s/it][INFO:swift] {'num_prompt_tokens': 1516, 'num_generated_tokens': 461, 'num_samples': 3, 'runtime': 20.01940347, 'samples/s': 0.14985462, 'tokens/s': 23.02765918}
INFO:     127.0.0.1:49106 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(prehistory):  80%|████████  | 4/5 [00:26<00:06,  6.91s/it][INFO:swift] {'num_prompt_tokens': 480, 'num_generated_tokens': 102, 'num_samples': 1, 'runtime': 20.02016133, 'samples/s': 0.04994965, 'tokens/s': 5.09486404}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01929059, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.0099956, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01759846, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:43464 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(prehistory): 100%|██████████| 5/5 [01:56<00:00, 36.80s/it]Predicting(prehistory): 100%|██████████| 5/5 [01:56<00:00, 23.27s/it]
2025-05-12 17:51:43,934 - evalscope - INFO - Dump predictions to /home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline/native/20250512_155825/predictions/Qwen2.5-3B/mmlu_prehistory.jsonl.
Reviewing(prehistory):   0%|          | 0/5 [00:00<?, ?it/s]Reviewing(prehistory):  40%|████      | 2/5 [00:00<00:00,  8.19it/s]Reviewing(prehistory):  80%|████████  | 4/5 [00:00<00:00,  9.98it/s]Reviewing(prehistory): 100%|██████████| 5/5 [00:00<00:00, 10.18it/s]
Predicting(anatomy):   0%|          | 0/5 [00:00<?, ?it/s][INFO:swift] {'num_prompt_tokens': 479, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.00041737, 'samples/s': 0.04999896, 'tokens/s': 102.39786312}
INFO:     127.0.0.1:43464 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(anatomy):  20%|██        | 1/5 [00:13<00:52, 13.03s/it][INFO:swift] {'num_prompt_tokens': 357, 'num_generated_tokens': 294, 'num_samples': 1, 'runtime': 20.02014197, 'samples/s': 0.0499497, 'tokens/s': 14.68521054}
INFO:     127.0.0.1:48736 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(anatomy):  40%|████      | 2/5 [00:30<00:46, 15.56s/it][INFO:swift] {'num_prompt_tokens': 317, 'num_generated_tokens': 398, 'num_samples': 1, 'runtime': 20.01884805, 'samples/s': 0.04995292, 'tokens/s': 19.88126385}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01981571, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02013261, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02016549, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:48742 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(anatomy):  60%|██████    | 3/5 [01:59<01:38, 49.06s/it][INFO:swift] {'num_prompt_tokens': 329, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.02012661, 'samples/s': 0.04994973, 'tokens/s': 102.29705535}
INFO:     127.0.0.1:48746 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(anatomy):  80%|████████  | 4/5 [02:16<00:36, 36.63s/it][INFO:swift] {'num_prompt_tokens': 344, 'num_generated_tokens': 406, 'num_samples': 1, 'runtime': 20.01874404, 'samples/s': 0.04995318, 'tokens/s': 20.28099262}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01977098, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01903744, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01656061, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:48750 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(anatomy): 100%|██████████| 5/5 [03:45<00:00, 55.44s/it]Predicting(anatomy): 100%|██████████| 5/5 [03:45<00:00, 45.13s/it]
2025-05-12 17:55:30,078 - evalscope - INFO - Dump predictions to /home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline/native/20250512_155825/predictions/Qwen2.5-3B/mmlu_anatomy.jsonl.
Reviewing(anatomy):   0%|          | 0/5 [00:00<?, ?it/s]Reviewing(anatomy):  20%|██        | 1/5 [00:00<00:00,  5.05it/s]Reviewing(anatomy): 100%|██████████| 5/5 [00:00<00:00, 18.86it/s]Reviewing(anatomy): 100%|██████████| 5/5 [00:00<00:00, 16.18it/s]
Predicting(human_sexuality):   0%|          | 0/5 [00:00<?, ?it/s][INFO:swift] {'num_prompt_tokens': 314, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.01961005, 'samples/s': 0.04995102, 'tokens/s': 102.29969489}
INFO:     127.0.0.1:38832 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(human_sexuality):  20%|██        | 1/5 [00:04<00:19,  4.87s/it][INFO:swift] {'num_prompt_tokens': 386, 'num_generated_tokens': 102, 'num_samples': 1, 'runtime': 20.01984223, 'samples/s': 0.04995044, 'tokens/s': 5.09494525}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01985439, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.0197773, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.00747992, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:48750 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(human_sexuality):  40%|████      | 2/5 [01:34<02:43, 54.58s/it][INFO:swift] {'num_prompt_tokens': 346, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.01171138, 'samples/s': 0.04997074, 'tokens/s': 102.34007285}
INFO:     127.0.0.1:38846 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(human_sexuality):  60%|██████    | 3/5 [01:51<01:14, 37.45s/it][INFO:swift] {'num_prompt_tokens': 361, 'num_generated_tokens': 389, 'num_samples': 1, 'runtime': 20.01982476, 'samples/s': 0.04995049, 'tokens/s': 19.43073952}
INFO:     127.0.0.1:38820 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(human_sexuality):  80%|████████  | 4/5 [02:04<00:27, 27.90s/it]INFO:     127.0.0.1:38856 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(human_sexuality): 100%|██████████| 5/5 [02:14<00:00, 21.43s/it]Predicting(human_sexuality): 100%|██████████| 5/5 [02:14<00:00, 26.91s/it]
2025-05-12 17:57:44,939 - evalscope - INFO - Dump predictions to /home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline/native/20250512_155825/predictions/Qwen2.5-3B/mmlu_human_sexuality.jsonl.
Reviewing(human_sexuality):   0%|          | 0/5 [00:00<?, ?it/s]Reviewing(human_sexuality): 100%|██████████| 5/5 [00:00<00:00, 40.11it/s]Reviewing(human_sexuality): 100%|██████████| 5/5 [00:00<00:00, 39.96it/s]
Predicting(college_medicine):   0%|          | 0/5 [00:00<?, ?it/s][INFO:swift] {'num_prompt_tokens': 700, 'num_generated_tokens': 531, 'num_samples': 2, 'runtime': 20.01980696, 'samples/s': 0.09990106, 'tokens/s': 26.52373227}
INFO:     127.0.0.1:38856 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(college_medicine):  20%|██        | 1/5 [00:15<01:01, 15.36s/it]INFO:     127.0.0.1:53870 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(college_medicine):  40%|████      | 2/5 [00:17<00:23,  7.73s/it][INFO:swift] {'num_prompt_tokens': 891, 'num_generated_tokens': 390, 'num_samples': 2, 'runtime': 20.0201356, 'samples/s': 0.09989942, 'tokens/s': 19.48038754}
INFO:     127.0.0.1:53876 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(college_medicine):  60%|██████    | 3/5 [00:40<00:29, 14.54s/it][INFO:swift] {'num_prompt_tokens': 445, 'num_generated_tokens': 522, 'num_samples': 1, 'runtime': 20.01932531, 'samples/s': 0.04995173, 'tokens/s': 26.07480481}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02026789, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01941981, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01993078, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01954563, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:53880 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(college_medicine):  80%|████████  | 4/5 [02:10<00:44, 44.47s/it]INFO:     127.0.0.1:53884 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(college_medicine): 100%|██████████| 5/5 [02:12<00:00, 29.23s/it]Predicting(college_medicine): 100%|██████████| 5/5 [02:12<00:00, 26.59s/it]
2025-05-12 17:59:58,034 - evalscope - INFO - Dump predictions to /home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline/native/20250512_155825/predictions/Qwen2.5-3B/mmlu_college_medicine.jsonl.
Reviewing(college_medicine):   0%|          | 0/5 [00:00<?, ?it/s]Reviewing(college_medicine): 100%|██████████| 5/5 [00:00<00:00, 58.53it/s]
Predicting(high_school_government_and_politics):   0%|          | 0/5 [00:00<?, ?it/s]INFO:     127.0.0.1:53884 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_government_and_politics):  20%|██        | 1/5 [00:00<00:02,  1.36it/s]INFO:     127.0.0.1:53880 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_government_and_politics):  40%|████      | 2/5 [00:01<00:02,  1.26it/s]INFO:     127.0.0.1:48006 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_government_and_politics):  60%|██████    | 3/5 [00:02<00:01,  1.39it/s]INFO:     127.0.0.1:48018 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_government_and_politics):  80%|████████  | 4/5 [00:02<00:00,  1.42it/s]INFO:     127.0.0.1:48024 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_government_and_politics): 100%|██████████| 5/5 [00:03<00:00,  1.46it/s]Predicting(high_school_government_and_politics): 100%|██████████| 5/5 [00:03<00:00,  1.42it/s]
2025-05-12 18:00:01,661 - evalscope - INFO - Dump predictions to /home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline/native/20250512_155825/predictions/Qwen2.5-3B/mmlu_high_school_government_and_politics.jsonl.
Reviewing(high_school_government_and_politics):   0%|          | 0/5 [00:00<?, ?it/s]Reviewing(high_school_government_and_politics): 100%|██████████| 5/5 [00:00<00:00, 164.64it/s]
Predicting(college_chemistry):   0%|          | 0/5 [00:00<?, ?it/s][INFO:swift] {'num_prompt_tokens': 3157, 'num_generated_tokens': 2115, 'num_samples': 7, 'runtime': 20.02012639, 'samples/s': 0.34964814, 'tokens/s': 105.64368871}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02013771, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02019235, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02015713, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02013519, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:53880 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(college_chemistry):  20%|██        | 1/5 [01:30<06:01, 90.35s/it][INFO:swift] {'num_prompt_tokens': 510, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.02015591, 'samples/s': 0.04994966, 'tokens/s': 102.29690564}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01755845, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01985744, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01959912, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:53884 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(college_chemistry):  40%|████      | 2/5 [03:00<04:30, 90.10s/it][INFO:swift] {'num_prompt_tokens': 483, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.0049776, 'samples/s': 0.04998756, 'tokens/s': 102.37452101}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01863269, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01987696, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02017685, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02017529, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:48006 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(college_chemistry):  60%|██████    | 3/5 [04:31<03:00, 90.49s/it]INFO:     127.0.0.1:48018 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(college_chemistry):  80%|████████  | 4/5 [04:48<01:01, 61.52s/it][INFO:swift] {'num_prompt_tokens': 1035, 'num_generated_tokens': 2443, 'num_samples': 2, 'runtime': 20.01871618, 'samples/s': 0.09990651, 'tokens/s': 122.03579782}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02017384, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01945257, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01899934, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01625318, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:48024 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(college_chemistry): 100%|██████████| 5/5 [06:18<00:00, 71.97s/it]Predicting(college_chemistry): 100%|██████████| 5/5 [06:18<00:00, 75.77s/it]
2025-05-12 18:06:20,540 - evalscope - INFO - Dump predictions to /home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline/native/20250512_155825/predictions/Qwen2.5-3B/mmlu_college_chemistry.jsonl.
Reviewing(college_chemistry):   0%|          | 0/5 [00:00<?, ?it/s]Reviewing(college_chemistry):  80%|████████  | 4/5 [00:00<00:00, 34.39it/s]Reviewing(college_chemistry): 100%|██████████| 5/5 [00:00<00:00, 34.83it/s]
Predicting(logical_fallacies):   0%|          | 0/5 [00:00<?, ?it/s][INFO:swift] {'num_prompt_tokens': 519, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.01987194, 'samples/s': 0.04995037, 'tokens/s': 102.29835667}
INFO:     127.0.0.1:48024 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(logical_fallacies):  20%|██        | 1/5 [00:19<01:16, 19.22s/it][INFO:swift] {'num_prompt_tokens': 461, 'num_generated_tokens': 440, 'num_samples': 1, 'runtime': 20.01977929, 'samples/s': 0.0499506, 'tokens/s': 21.97826427}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01968405, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01956492, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01984321, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:38370 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(logical_fallacies):  40%|████      | 2/5 [01:48<03:01, 60.64s/it][INFO:swift] {'num_prompt_tokens': 434, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.0198206, 'samples/s': 0.0499505, 'tokens/s': 102.29861899}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02018415, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01925203, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01977898, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01982833, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:38382 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(logical_fallacies):  60%|██████    | 3/5 [03:18<02:28, 74.01s/it][INFO:swift] {'num_prompt_tokens': 458, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.01984474, 'samples/s': 0.04995044, 'tokens/s': 102.29849567}
INFO:     127.0.0.1:38396 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(logical_fallacies):  80%|████████  | 4/5 [03:47<00:56, 56.28s/it][INFO:swift] {'num_prompt_tokens': 459, 'num_generated_tokens': 676, 'num_samples': 1, 'runtime': 20.01986974, 'samples/s': 0.04995037, 'tokens/s': 33.76645346}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02015251, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01935554, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01570079, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.0199914, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:38404 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(logical_fallacies): 100%|██████████| 5/5 [05:17<00:00, 68.30s/it]Predicting(logical_fallacies): 100%|██████████| 5/5 [05:17<00:00, 63.50s/it]
2025-05-12 18:11:38,203 - evalscope - INFO - Dump predictions to /home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline/native/20250512_155825/predictions/Qwen2.5-3B/mmlu_logical_fallacies.jsonl.
Reviewing(logical_fallacies):   0%|          | 0/5 [00:00<?, ?it/s]Reviewing(logical_fallacies):  40%|████      | 2/5 [00:00<00:00, 18.05it/s]Reviewing(logical_fallacies):  80%|████████  | 4/5 [00:00<00:00, 15.37it/s]Reviewing(logical_fallacies): 100%|██████████| 5/5 [00:00<00:00, 12.31it/s]
Predicting(high_school_geography):   0%|          | 0/5 [00:00<?, ?it/s][INFO:swift] {'num_prompt_tokens': 415, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.01975046, 'samples/s': 0.04995067, 'tokens/s': 102.29897739}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.0201911, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01968938, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01947913, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:38404 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_geography):  20%|██        | 1/5 [01:29<05:56, 89.23s/it][INFO:swift] {'num_prompt_tokens': 355, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.02017803, 'samples/s': 0.04994961, 'tokens/s': 102.29679264}
INFO:     127.0.0.1:42242 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_geography):  40%|████      | 2/5 [01:51<02:29, 49.93s/it][INFO:swift] {'num_prompt_tokens': 344, 'num_generated_tokens': 518, 'num_samples': 1, 'runtime': 20.02014384, 'samples/s': 0.04994969, 'tokens/s': 25.87393997}
INFO:     127.0.0.1:42248 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_geography):  60%|██████    | 3/5 [02:06<01:07, 33.87s/it][INFO:swift] {'num_prompt_tokens': 355, 'num_generated_tokens': 333, 'num_samples': 1, 'runtime': 20.01908565, 'samples/s': 0.04995233, 'tokens/s': 16.63412634}
INFO:     127.0.0.1:42256 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_geography):  80%|████████  | 4/5 [02:23<00:27, 27.09s/it]INFO:     127.0.0.1:42268 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_geography): 100%|██████████| 5/5 [02:23<00:00, 17.55s/it]Predicting(high_school_geography): 100%|██████████| 5/5 [02:23<00:00, 28.75s/it]
2025-05-12 18:14:02,354 - evalscope - INFO - Dump predictions to /home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline/native/20250512_155825/predictions/Qwen2.5-3B/mmlu_high_school_geography.jsonl.
Reviewing(high_school_geography):   0%|          | 0/5 [00:00<?, ?it/s]Reviewing(high_school_geography): 100%|██████████| 5/5 [00:00<00:00, 51.44it/s]
Predicting(elementary_mathematics):   0%|          | 0/5 [00:00<?, ?it/s][INFO:swift] {'num_prompt_tokens': 727, 'num_generated_tokens': 393, 'num_samples': 2, 'runtime': 20.01988316, 'samples/s': 0.09990068, 'tokens/s': 19.6304842}
INFO:     127.0.0.1:42256 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(elementary_mathematics):  20%|██        | 1/5 [00:20<01:23, 20.89s/it][INFO:swift] {'num_prompt_tokens': 546, 'num_generated_tokens': 476, 'num_samples': 1, 'runtime': 20.01976361, 'samples/s': 0.04995064, 'tokens/s': 23.77650452}
INFO:     127.0.0.1:42268 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(elementary_mathematics):  40%|████      | 2/5 [00:35<00:51, 17.22s/it]INFO:     127.0.0.1:33864 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(elementary_mathematics):  60%|██████    | 3/5 [00:48<00:30, 15.50s/it][INFO:swift] {'num_prompt_tokens': 1116, 'num_generated_tokens': 630, 'num_samples': 2, 'runtime': 20.00655415, 'samples/s': 0.09996724, 'tokens/s': 31.4896806}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.00739143, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02013784, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.0201656, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01675857, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:33862 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(elementary_mathematics):  80%|████████  | 4/5 [02:19<00:45, 45.07s/it][INFO:swift] {'num_prompt_tokens': 549, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.01963101, 'samples/s': 0.04995097, 'tokens/s': 102.29958778}
INFO:     127.0.0.1:33868 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(elementary_mathematics): 100%|██████████| 5/5 [02:40<00:00, 36.31s/it]Predicting(elementary_mathematics): 100%|██████████| 5/5 [02:40<00:00, 32.03s/it]
2025-05-12 18:16:42,621 - evalscope - INFO - Dump predictions to /home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline/native/20250512_155825/predictions/Qwen2.5-3B/mmlu_elementary_mathematics.jsonl.
Reviewing(elementary_mathematics):   0%|          | 0/5 [00:00<?, ?it/s]Reviewing(elementary_mathematics): 100%|██████████| 5/5 [00:00<00:00, 103.23it/s]
Predicting(human_aging):   0%|          | 0/5 [00:00<?, ?it/s][INFO:swift] {'num_prompt_tokens': 552, 'num_generated_tokens': 477, 'num_samples': 1, 'runtime': 20.01983771, 'samples/s': 0.04995045, 'tokens/s': 23.82636698}
INFO:     127.0.0.1:33868 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(human_aging):  20%|██        | 1/5 [00:13<00:52, 13.14s/it][INFO:swift] {'num_prompt_tokens': 308, 'num_generated_tokens': 300, 'num_samples': 1, 'runtime': 20.01679466, 'samples/s': 0.04995805, 'tokens/s': 14.98741457}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02018905, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01832695, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.0201288, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:53468 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(human_aging):  40%|████      | 2/5 [01:42<02:53, 57.84s/it][INFO:swift] {'num_prompt_tokens': 326, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.01932325, 'samples/s': 0.04995174, 'tokens/s': 102.30116046}
INFO:     127.0.0.1:53480 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(human_aging):  60%|██████    | 3/5 [01:52<01:12, 36.12s/it][INFO:swift] {'num_prompt_tokens': 301, 'num_generated_tokens': 234, 'num_samples': 1, 'runtime': 20.00995137, 'samples/s': 0.04997513, 'tokens/s': 11.69418134}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01780645, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01948402, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02013856, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:53490 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(human_aging):  80%|████████  | 4/5 [03:21<00:56, 56.93s/it][INFO:swift] {'num_prompt_tokens': 315, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.02017554, 'samples/s': 0.04994961, 'tokens/s': 102.29680536}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01913771, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01968948, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01959944, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01437973, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:53500 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(human_aging): 100%|██████████| 5/5 [04:50<00:00, 68.49s/it]Predicting(human_aging): 100%|██████████| 5/5 [04:50<00:00, 58.07s/it]
2025-05-12 18:21:33,043 - evalscope - INFO - Dump predictions to /home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline/native/20250512_155825/predictions/Qwen2.5-3B/mmlu_human_aging.jsonl.
Reviewing(human_aging):   0%|          | 0/5 [00:00<?, ?it/s]Reviewing(human_aging):  60%|██████    | 3/5 [00:00<00:00, 28.30it/s]Reviewing(human_aging): 100%|██████████| 5/5 [00:00<00:00, 28.65it/s]
Predicting(college_mathematics):   0%|          | 0/5 [00:00<?, ?it/s][INFO:swift] {'num_prompt_tokens': 337, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.0173244, 'samples/s': 0.04995673, 'tokens/s': 102.31137586}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01988437, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.00478983, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01854958, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:53500 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(college_mathematics):  20%|██        | 1/5 [01:20<05:20, 80.19s/it][INFO:swift] {'num_prompt_tokens': 528, 'num_generated_tokens': 1833, 'num_samples': 1, 'runtime': 20.01975473, 'samples/s': 0.04995066, 'tokens/s': 91.55956329}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02017353, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02015351, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.0188218, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:56798 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(college_mathematics):  40%|████      | 2/5 [02:51<04:19, 86.52s/it][INFO:swift] {'num_prompt_tokens': 576, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.02011722, 'samples/s': 0.04994976, 'tokens/s': 102.29710335}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.00254319, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01686627, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01955287, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01976008, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:56812 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(college_mathematics):  60%|██████    | 3/5 [04:21<02:56, 88.20s/it]INFO:     127.0.0.1:56828 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(college_mathematics):  80%|████████  | 4/5 [04:32<00:57, 57.82s/it][INFO:swift] {'num_prompt_tokens': 1047, 'num_generated_tokens': 2297, 'num_samples': 2, 'runtime': 20.00158393, 'samples/s': 0.09999208, 'tokens/s': 114.84090502}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01812687, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01968924, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01965778, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.0198296, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:56832 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(college_mathematics): 100%|██████████| 5/5 [06:03<00:00, 69.74s/it]Predicting(college_mathematics): 100%|██████████| 5/5 [06:03<00:00, 72.70s/it]
2025-05-12 18:27:36,707 - evalscope - INFO - Dump predictions to /home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline/native/20250512_155825/predictions/Qwen2.5-3B/mmlu_college_mathematics.jsonl.
Reviewing(college_mathematics):   0%|          | 0/5 [00:00<?, ?it/s]Reviewing(college_mathematics): 100%|██████████| 5/5 [00:00<00:00, 88.66it/s]
Predicting(high_school_psychology):   0%|          | 0/5 [00:00<?, ?it/s]INFO:     127.0.0.1:56832 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_psychology):  20%|██        | 1/5 [00:03<00:13,  3.30s/it]INFO:     127.0.0.1:34684 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_psychology):  40%|████      | 2/5 [00:10<00:16,  5.64s/it]INFO:     127.0.0.1:34696 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_psychology):  60%|██████    | 3/5 [00:11<00:06,  3.33s/it]INFO:     127.0.0.1:34710 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_psychology):  80%|████████  | 4/5 [00:11<00:02,  2.30s/it]INFO:     127.0.0.1:34716 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_psychology): 100%|██████████| 5/5 [00:12<00:00,  1.71s/it]Predicting(high_school_psychology): 100%|██████████| 5/5 [00:12<00:00,  2.51s/it]
2025-05-12 18:27:49,325 - evalscope - INFO - Dump predictions to /home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline/native/20250512_155825/predictions/Qwen2.5-3B/mmlu_high_school_psychology.jsonl.
Reviewing(high_school_psychology):   0%|          | 0/5 [00:00<?, ?it/s]Reviewing(high_school_psychology): 100%|██████████| 5/5 [00:00<00:00, 65.06it/s]
Predicting(formal_logic):   0%|          | 0/5 [00:00<?, ?it/s][INFO:swift] {'num_prompt_tokens': 2949, 'num_generated_tokens': 2277, 'num_samples': 6, 'runtime': 20.01981916, 'samples/s': 0.29970301, 'tokens/s': 113.73729113}
INFO:     127.0.0.1:34684 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(formal_logic):  20%|██        | 1/5 [00:13<00:55, 13.86s/it][INFO:swift] {'num_prompt_tokens': 537, 'num_generated_tokens': 305, 'num_samples': 1, 'runtime': 20.01991966, 'samples/s': 0.04995025, 'tokens/s': 15.23482637}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01951464, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02015026, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.00368083, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01962988, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:34696 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(formal_logic):  40%|████      | 2/5 [01:44<02:57, 59.01s/it][INFO:swift] {'num_prompt_tokens': 596, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.01978408, 'samples/s': 0.04995059, 'tokens/s': 102.29880559}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01824288, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01735824, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.0201358, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:34710 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(formal_logic):  60%|██████    | 3/5 [03:15<02:27, 73.64s/it][INFO:swift] {'num_prompt_tokens': 597, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.01942147, 'samples/s': 0.04995149, 'tokens/s': 102.30065853}
INFO:     127.0.0.1:34716 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(formal_logic):  80%|████████  | 4/5 [03:38<00:53, 53.45s/it][INFO:swift] {'num_prompt_tokens': 636, 'num_generated_tokens': 516, 'num_samples': 1, 'runtime': 20.01960953, 'samples/s': 0.04995102, 'tokens/s': 25.77472849}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02044826, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01912012, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01983173, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01964639, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:60106 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(formal_logic): 100%|██████████| 5/5 [05:09<00:00, 66.99s/it]Predicting(formal_logic): 100%|██████████| 5/5 [05:09<00:00, 61.81s/it]
2025-05-12 18:32:58,437 - evalscope - INFO - Dump predictions to /home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline/native/20250512_155825/predictions/Qwen2.5-3B/mmlu_formal_logic.jsonl.
Reviewing(formal_logic):   0%|          | 0/5 [00:00<?, ?it/s]Reviewing(formal_logic):  20%|██        | 1/5 [00:00<00:00,  8.05it/s]Reviewing(formal_logic):  60%|██████    | 3/5 [00:00<00:00, 11.61it/s]Reviewing(formal_logic): 100%|██████████| 5/5 [00:00<00:00, 13.06it/s]Reviewing(formal_logic): 100%|██████████| 5/5 [00:00<00:00, 12.34it/s]
Predicting(high_school_statistics):   0%|          | 0/5 [00:00<?, ?it/s][INFO:swift] {'num_prompt_tokens': 588, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.0196916, 'samples/s': 0.04995082, 'tokens/s': 102.29927816}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01971921, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02018501, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01949085, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:60106 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_statistics):  20%|██        | 1/5 [01:32<06:11, 92.87s/it][INFO:swift] {'num_prompt_tokens': 769, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.02016586, 'samples/s': 0.04994964, 'tokens/s': 102.29685479}
INFO:     127.0.0.1:60488 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_statistics):  40%|████      | 2/5 [01:45<02:16, 45.50s/it]INFO:     127.0.0.1:60498 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_statistics):  60%|██████    | 3/5 [01:47<00:51, 25.78s/it][INFO:swift] {'num_prompt_tokens': 1489, 'num_generated_tokens': 305, 'num_samples': 2, 'runtime': 20.01930753, 'samples/s': 0.09990356, 'tokens/s': 15.23529221}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.0198132, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.0201498, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01952458, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01959052, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:60514 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_statistics):  80%|████████  | 4/5 [03:19<00:52, 52.00s/it][INFO:swift] {'num_prompt_tokens': 712, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.02014097, 'samples/s': 0.0499497, 'tokens/s': 102.29698196}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.0194399, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01985415, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01971919, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:60520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_statistics): 100%|██████████| 5/5 [04:53<00:00, 67.13s/it]Predicting(high_school_statistics): 100%|██████████| 5/5 [04:53<00:00, 58.73s/it]
2025-05-12 18:37:52,520 - evalscope - INFO - Dump predictions to /home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline/native/20250512_155825/predictions/Qwen2.5-3B/mmlu_high_school_statistics.jsonl.
Reviewing(high_school_statistics):   0%|          | 0/5 [00:00<?, ?it/s]Reviewing(high_school_statistics):  80%|████████  | 4/5 [00:00<00:00, 37.62it/s]Reviewing(high_school_statistics): 100%|██████████| 5/5 [00:00<00:00, 38.94it/s]
Predicting(international_law):   0%|          | 0/5 [00:00<?, ?it/s][INFO:swift] {'num_prompt_tokens': 892, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.01956332, 'samples/s': 0.04995114, 'tokens/s': 102.29993367}
INFO:     127.0.0.1:60520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(international_law):  20%|██        | 1/5 [00:04<00:19,  4.90s/it]INFO:     127.0.0.1:45688 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(international_law):  40%|████      | 2/5 [00:09<00:14,  4.71s/it]INFO:     127.0.0.1:45704 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(international_law):  60%|██████    | 3/5 [00:11<00:06,  3.46s/it]INFO:     127.0.0.1:45714 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(international_law):  80%|████████  | 4/5 [00:14<00:03,  3.15s/it]INFO:     127.0.0.1:45728 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(international_law): 100%|██████████| 5/5 [00:17<00:00,  3.29s/it]Predicting(international_law): 100%|██████████| 5/5 [00:17<00:00,  3.53s/it]
2025-05-12 18:38:10,335 - evalscope - INFO - Dump predictions to /home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline/native/20250512_155825/predictions/Qwen2.5-3B/mmlu_international_law.jsonl.
Reviewing(international_law):   0%|          | 0/5 [00:00<?, ?it/s]Reviewing(international_law): 100%|██████████| 5/5 [00:00<00:00, 41.58it/s]Reviewing(international_law): 100%|██████████| 5/5 [00:00<00:00, 41.43it/s]
Predicting(high_school_mathematics):   0%|          | 0/5 [00:00<?, ?it/s][INFO:swift] {'num_prompt_tokens': 3046, 'num_generated_tokens': 335, 'num_samples': 5, 'runtime': 20.01980074, 'samples/s': 0.24975274, 'tokens/s': 16.73343328}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.0091214, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:45714 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_mathematics):  20%|██        | 1/5 [00:25<01:40, 25.24s/it][INFO:swift] {'num_prompt_tokens': 487, 'num_generated_tokens': 577, 'num_samples': 1, 'runtime': 20.01851342, 'samples/s': 0.04995376, 'tokens/s': 28.82331908}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01456675, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02014709, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01650197, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:45728 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_mathematics):  40%|████      | 2/5 [01:55<03:10, 63.61s/it][INFO:swift] {'num_prompt_tokens': 496, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.0198908, 'samples/s': 0.04995032, 'tokens/s': 102.29826029}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01959952, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.0201592, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01540169, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.00699773, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:50976 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_mathematics):  60%|██████    | 3/5 [03:26<02:31, 75.85s/it][INFO:swift] {'num_prompt_tokens': 504, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.01661867, 'samples/s': 0.04995849, 'tokens/s': 102.31498305}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01275278, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01860509, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02013766, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:50986 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_mathematics):  80%|████████  | 4/5 [04:56<01:21, 81.56s/it][INFO:swift] {'num_prompt_tokens': 515, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.01952217, 'samples/s': 0.04995124, 'tokens/s': 102.30014396}
INFO:     127.0.0.1:50994 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_mathematics): 100%|██████████| 5/5 [05:16<00:00, 59.46s/it]Predicting(high_school_mathematics): 100%|██████████| 5/5 [05:16<00:00, 63.34s/it]
2025-05-12 18:43:27,170 - evalscope - INFO - Dump predictions to /home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline/native/20250512_155825/predictions/Qwen2.5-3B/mmlu_high_school_mathematics.jsonl.
Reviewing(high_school_mathematics):   0%|          | 0/5 [00:00<?, ?it/s]Reviewing(high_school_mathematics):  40%|████      | 2/5 [00:00<00:00, 14.16it/s]Reviewing(high_school_mathematics): 100%|██████████| 5/5 [00:00<00:00, 18.20it/s]Reviewing(high_school_mathematics): 100%|██████████| 5/5 [00:00<00:00, 17.57it/s]
Predicting(high_school_computer_science):   0%|          | 0/5 [00:00<?, ?it/s]INFO:     127.0.0.1:50994 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_computer_science):  20%|██        | 1/5 [00:05<00:23,  5.89s/it][INFO:swift] {'num_prompt_tokens': 1355, 'num_generated_tokens': 579, 'num_samples': 2, 'runtime': 20.02017704, 'samples/s': 0.09989922, 'tokens/s': 28.92082317}
INFO:     127.0.0.1:32860 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_computer_science):  40%|████      | 2/5 [00:15<00:23,  7.82s/it]INFO:     127.0.0.1:32874 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_computer_science):  60%|██████    | 3/5 [00:21<00:14,  7.24s/it][INFO:swift] {'num_prompt_tokens': 1823, 'num_generated_tokens': 326, 'num_samples': 2, 'runtime': 20.01926017, 'samples/s': 0.09990379, 'tokens/s': 16.28431807}
INFO:     127.0.0.1:32888 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_computer_science):  80%|████████  | 4/5 [00:27<00:06,  6.57s/it]INFO:     127.0.0.1:32902 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_computer_science): 100%|██████████| 5/5 [00:29<00:00,  4.98s/it]Predicting(high_school_computer_science): 100%|██████████| 5/5 [00:29<00:00,  5.86s/it]
2025-05-12 18:43:56,785 - evalscope - INFO - Dump predictions to /home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline/native/20250512_155825/predictions/Qwen2.5-3B/mmlu_high_school_computer_science.jsonl.
Reviewing(high_school_computer_science):   0%|          | 0/5 [00:00<?, ?it/s]Reviewing(high_school_computer_science): 100%|██████████| 5/5 [00:00<00:00, 95.71it/s]
Predicting(conceptual_physics):   0%|          | 0/5 [00:00<?, ?it/s]INFO:     127.0.0.1:32888 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(conceptual_physics):  20%|██        | 1/5 [00:03<00:13,  3.27s/it][INFO:swift] {'num_prompt_tokens': 1944, 'num_generated_tokens': 209, 'num_samples': 3, 'runtime': 20.02016555, 'samples/s': 0.14984891, 'tokens/s': 10.43947411}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02017144, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01901195, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01162709, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:32902 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(conceptual_physics):  40%|████      | 2/5 [01:31<02:40, 53.51s/it][INFO:swift] {'num_prompt_tokens': 319, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.00774939, 'samples/s': 0.04998063, 'tokens/s': 102.36033849}
INFO:     127.0.0.1:46348 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(conceptual_physics):  60%|██████    | 3/5 [01:44<01:09, 34.77s/it]INFO:     127.0.0.1:46358 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(conceptual_physics):  80%|████████  | 4/5 [01:53<00:24, 24.51s/it][INFO:swift] {'num_prompt_tokens': 616, 'num_generated_tokens': 488, 'num_samples': 2, 'runtime': 20.01581156, 'samples/s': 0.099921, 'tokens/s': 24.38072513}
INFO:     127.0.0.1:46360 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(conceptual_physics): 100%|██████████| 5/5 [02:07<00:00, 20.79s/it]Predicting(conceptual_physics): 100%|██████████| 5/5 [02:07<00:00, 25.48s/it]
2025-05-12 18:46:04,235 - evalscope - INFO - Dump predictions to /home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline/native/20250512_155825/predictions/Qwen2.5-3B/mmlu_conceptual_physics.jsonl.
Reviewing(conceptual_physics):   0%|          | 0/5 [00:00<?, ?it/s]Reviewing(conceptual_physics): 100%|██████████| 5/5 [00:00<00:00, 47.94it/s]Reviewing(conceptual_physics): 100%|██████████| 5/5 [00:00<00:00, 47.73it/s]
Predicting(miscellaneous):   0%|          | 0/5 [00:00<?, ?it/s][INFO:swift] {'num_prompt_tokens': 297, 'num_generated_tokens': 326, 'num_samples': 1, 'runtime': 20.01399268, 'samples/s': 0.04996504, 'tokens/s': 16.28860394}
INFO:     127.0.0.1:59930 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(miscellaneous):  20%|██        | 1/5 [00:10<00:42, 10.64s/it]INFO:     127.0.0.1:46360 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(miscellaneous):  40%|████      | 2/5 [00:13<00:18,  6.12s/it]INFO:     127.0.0.1:59946 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(miscellaneous):  60%|██████    | 3/5 [00:14<00:07,  3.85s/it]INFO:     127.0.0.1:59928 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(miscellaneous):  80%|████████  | 4/5 [00:15<00:02,  2.66s/it]INFO:     127.0.0.1:59954 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(miscellaneous): 100%|██████████| 5/5 [00:17<00:00,  2.47s/it]Predicting(miscellaneous): 100%|██████████| 5/5 [00:17<00:00,  3.54s/it]
2025-05-12 18:46:22,052 - evalscope - INFO - Dump predictions to /home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline/native/20250512_155825/predictions/Qwen2.5-3B/mmlu_miscellaneous.jsonl.
Reviewing(miscellaneous):   0%|          | 0/5 [00:00<?, ?it/s]Reviewing(miscellaneous): 100%|██████████| 5/5 [00:00<00:00, 50.10it/s]
Predicting(high_school_chemistry):   0%|          | 0/5 [00:00<?, ?it/s][INFO:swift] {'num_prompt_tokens': 1639, 'num_generated_tokens': 371, 'num_samples': 5, 'runtime': 20.02018694, 'samples/s': 0.24974792, 'tokens/s': 18.53129549}
INFO:     127.0.0.1:46360 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_chemistry):  20%|██        | 1/5 [00:15<01:02, 15.68s/it]INFO:     127.0.0.1:59928 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_chemistry):  40%|████      | 2/5 [00:30<00:45, 15.10s/it][INFO:swift] {'num_prompt_tokens': 1034, 'num_generated_tokens': 689, 'num_samples': 2, 'runtime': 20.02013987, 'samples/s': 0.0998994, 'tokens/s': 34.41534398}
INFO:     127.0.0.1:59946 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_chemistry):  60%|██████    | 3/5 [00:44<00:29, 14.84s/it][INFO:swift] {'num_prompt_tokens': 548, 'num_generated_tokens': 327, 'num_samples': 1, 'runtime': 20.01689503, 'samples/s': 0.0499578, 'tokens/s': 16.33619997}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01175486, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.0198552, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02015595, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02014651, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:58474 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_chemistry):  80%|████████  | 4/5 [02:15<00:44, 44.71s/it]INFO:     127.0.0.1:59954 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_chemistry): 100%|██████████| 5/5 [02:24<00:00, 31.75s/it]Predicting(high_school_chemistry): 100%|██████████| 5/5 [02:24<00:00, 28.83s/it]
2025-05-12 18:48:46,319 - evalscope - INFO - Dump predictions to /home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline/native/20250512_155825/predictions/Qwen2.5-3B/mmlu_high_school_chemistry.jsonl.
Reviewing(high_school_chemistry):   0%|          | 0/5 [00:00<?, ?it/s]Reviewing(high_school_chemistry):  60%|██████    | 3/5 [00:00<00:00, 20.04it/s]Reviewing(high_school_chemistry): 100%|██████████| 5/5 [00:00<00:00, 15.49it/s]
Predicting(marketing):   0%|          | 0/5 [00:00<?, ?it/s][INFO:swift] {'num_prompt_tokens': 1005, 'num_generated_tokens': 2243, 'num_samples': 2, 'runtime': 20.02013435, 'samples/s': 0.09989943, 'tokens/s': 112.03721018}
INFO:     127.0.0.1:55764 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(marketing):  20%|██        | 1/5 [00:14<00:59, 14.94s/it]INFO:     127.0.0.1:55754 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(marketing):  40%|████      | 2/5 [00:19<00:27,  9.03s/it]INFO:     127.0.0.1:59954 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(marketing):  60%|██████    | 3/5 [00:20<00:10,  5.14s/it]INFO:     127.0.0.1:55768 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(marketing):  80%|████████  | 4/5 [00:21<00:03,  3.69s/it]INFO:     127.0.0.1:55770 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(marketing): 100%|██████████| 5/5 [00:22<00:00,  2.57s/it]Predicting(marketing): 100%|██████████| 5/5 [00:22<00:00,  4.48s/it]
2025-05-12 18:49:09,042 - evalscope - INFO - Dump predictions to /home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline/native/20250512_155825/predictions/Qwen2.5-3B/mmlu_marketing.jsonl.
Reviewing(marketing):   0%|          | 0/5 [00:00<?, ?it/s]Reviewing(marketing):  80%|████████  | 4/5 [00:00<00:00, 36.54it/s]Reviewing(marketing): 100%|██████████| 5/5 [00:00<00:00, 37.75it/s]
Predicting(professional_law):   0%|          | 0/5 [00:00<?, ?it/s][INFO:swift] {'num_prompt_tokens': 2120, 'num_generated_tokens': 472, 'num_samples': 5, 'runtime': 20.01864753, 'samples/s': 0.24976712, 'tokens/s': 23.57801641}
INFO:     127.0.0.1:55768 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(professional_law):  20%|██        | 1/5 [00:11<00:46, 11.62s/it]INFO:     127.0.0.1:59954 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(professional_law):  40%|████      | 2/5 [00:21<00:30, 10.32s/it][INFO:swift] {'num_prompt_tokens': 2835, 'num_generated_tokens': 424, 'num_samples': 2, 'runtime': 20.01959913, 'samples/s': 0.0999021, 'tokens/s': 21.17924526}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01366287, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01798961, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01977158, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.00770273, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:55754 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(professional_law):  60%|██████    | 3/5 [02:01<01:42, 51.26s/it][INFO:swift] {'num_prompt_tokens': 1343, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.01964507, 'samples/s': 0.04995094, 'tokens/s': 102.29951594}
INFO:     127.0.0.1:55770 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(professional_law):  80%|████████  | 4/5 [02:16<00:37, 37.24s/it]INFO:     127.0.0.1:60180 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(professional_law): 100%|██████████| 5/5 [02:20<00:00, 25.09s/it]Predicting(professional_law): 100%|██████████| 5/5 [02:20<00:00, 28.06s/it]
2025-05-12 18:51:29,494 - evalscope - INFO - Dump predictions to /home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline/native/20250512_155825/predictions/Qwen2.5-3B/mmlu_professional_law.jsonl.
Reviewing(professional_law):   0%|          | 0/5 [00:00<?, ?it/s]Reviewing(professional_law):  40%|████      | 2/5 [00:00<00:00,  5.05it/s]Reviewing(professional_law):  80%|████████  | 4/5 [00:00<00:00,  8.03it/s]Reviewing(professional_law): 100%|██████████| 5/5 [00:00<00:00,  7.98it/s]
Predicting(management):   0%|          | 0/5 [00:00<?, ?it/s][INFO:swift] {'num_prompt_tokens': 2612, 'num_generated_tokens': 386, 'num_samples': 2, 'runtime': 20.01981143, 'samples/s': 0.09990104, 'tokens/s': 19.28090089}
INFO:     127.0.0.1:55770 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(management):  20%|██        | 1/5 [00:07<00:28,  7.00s/it]INFO:     127.0.0.1:60180 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(management):  40%|████      | 2/5 [00:21<00:33, 11.27s/it]INFO:     127.0.0.1:39240 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(management):  60%|██████    | 3/5 [00:23<00:14,  7.01s/it][INFO:swift] {'num_prompt_tokens': 849, 'num_generated_tokens': 520, 'num_samples': 3, 'runtime': 20.02013245, 'samples/s': 0.14984916, 'tokens/s': 25.97385413}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01959535, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02014835, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01646405, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02019155, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:39246 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(management):  80%|████████  | 4/5 [01:51<00:39, 39.20s/it][INFO:swift] {'num_prompt_tokens': 281, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.02013103, 'samples/s': 0.04994972, 'tokens/s': 102.29703276}
INFO:     127.0.0.1:39260 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(management): 100%|██████████| 5/5 [02:07<00:00, 30.84s/it]Predicting(management): 100%|██████████| 5/5 [02:07<00:00, 25.55s/it]
2025-05-12 18:53:37,889 - evalscope - INFO - Dump predictions to /home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline/native/20250512_155825/predictions/Qwen2.5-3B/mmlu_management.jsonl.
Reviewing(management):   0%|          | 0/5 [00:00<?, ?it/s]Reviewing(management):  20%|██        | 1/5 [00:00<00:00,  4.26it/s]Reviewing(management):  60%|██████    | 3/5 [00:00<00:00,  8.39it/s]Reviewing(management): 100%|██████████| 5/5 [00:00<00:00, 10.46it/s]
Predicting(college_physics):   0%|          | 0/5 [00:00<?, ?it/s][INFO:swift] {'num_prompt_tokens': 273, 'num_generated_tokens': 367, 'num_samples': 1, 'runtime': 20.01735063, 'samples/s': 0.04995666, 'tokens/s': 18.33409459}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02004553, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01970989, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02013917, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:39260 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(college_physics):  20%|██        | 1/5 [01:30<06:00, 90.13s/it][INFO:swift] {'num_prompt_tokens': 509, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.01955354, 'samples/s': 0.04995116, 'tokens/s': 102.29998367}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02015561, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02014435, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02011258, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01860725, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:51880 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(college_physics):  40%|████      | 2/5 [03:00<04:30, 90.10s/it][INFO:swift] {'num_prompt_tokens': 485, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.01989761, 'samples/s': 0.04995031, 'tokens/s': 102.29822548}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02015531, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01857214, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02012823, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:51892 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(college_physics):  60%|██████    | 3/5 [04:29<02:59, 89.85s/it][INFO:swift] {'num_prompt_tokens': 460, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.02019612, 'samples/s': 0.04994956, 'tokens/s': 102.29670019}
INFO:     127.0.0.1:51898 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(college_physics):  80%|████████  | 4/5 [04:55<01:04, 64.56s/it][INFO:swift] {'num_prompt_tokens': 506, 'num_generated_tokens': 598, 'num_samples': 1, 'runtime': 20.01355965, 'samples/s': 0.04996612, 'tokens/s': 29.87974206}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01895542, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.0201207, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.0154811, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02018122, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:51912 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(college_physics): 100%|██████████| 5/5 [06:25<00:00, 73.65s/it]Predicting(college_physics): 100%|██████████| 5/5 [06:25<00:00, 77.06s/it]
2025-05-12 19:00:03,700 - evalscope - INFO - Dump predictions to /home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline/native/20250512_155825/predictions/Qwen2.5-3B/mmlu_college_physics.jsonl.
Reviewing(college_physics):   0%|          | 0/5 [00:00<?, ?it/s]Reviewing(college_physics):  60%|██████    | 3/5 [00:00<00:00, 22.49it/s]Reviewing(college_physics): 100%|██████████| 5/5 [00:00<00:00, 24.95it/s]
Predicting(jurisprudence):   0%|          | 0/5 [00:00<?, ?it/s][INFO:swift] {'num_prompt_tokens': 466, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.01765828, 'samples/s': 0.04995589, 'tokens/s': 102.30966935}
INFO:     127.0.0.1:51912 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(jurisprudence):  20%|██        | 1/5 [00:13<00:53, 13.36s/it]INFO:     127.0.0.1:38666 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(jurisprudence):  40%|████      | 2/5 [00:22<00:33, 11.16s/it][INFO:swift] {'num_prompt_tokens': 752, 'num_generated_tokens': 522, 'num_samples': 2, 'runtime': 20.02017443, 'samples/s': 0.09989923, 'tokens/s': 26.0736989}
INFO:     127.0.0.1:38682 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(jurisprudence):  60%|██████    | 3/5 [00:45<00:32, 16.14s/it][INFO:swift] {'num_prompt_tokens': 370, 'num_generated_tokens': 511, 'num_samples': 1, 'runtime': 20.01976224, 'samples/s': 0.04995064, 'tokens/s': 25.52477866}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02013867, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01957523, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01686111, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.015355, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:38696 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(jurisprudence):  80%|████████  | 4/5 [02:14<00:44, 44.91s/it]INFO:     127.0.0.1:38698 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(jurisprudence): 100%|██████████| 5/5 [02:14<00:00, 28.94s/it]Predicting(jurisprudence): 100%|██████████| 5/5 [02:14<00:00, 26.94s/it]
2025-05-12 19:02:18,593 - evalscope - INFO - Dump predictions to /home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline/native/20250512_155825/predictions/Qwen2.5-3B/mmlu_jurisprudence.jsonl.
Reviewing(jurisprudence):   0%|          | 0/5 [00:00<?, ?it/s]Reviewing(jurisprudence): 100%|██████████| 5/5 [00:00<00:00, 63.13it/s]
Predicting(world_religions):   0%|          | 0/5 [00:00<?, ?it/s]INFO:     127.0.0.1:38698 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(world_religions):  20%|██        | 1/5 [00:03<00:15,  3.95s/it][INFO:swift] {'num_prompt_tokens': 983, 'num_generated_tokens': 2136, 'num_samples': 3, 'runtime': 20.00447434, 'samples/s': 0.14996645, 'tokens/s': 106.77611238}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02019208, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:38696 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(world_religions):  40%|████      | 2/5 [00:48<01:23, 27.99s/it]INFO:     127.0.0.1:39584 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(world_religions):  60%|██████    | 3/5 [00:53<00:34, 17.16s/it]INFO:     127.0.0.1:39592 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(world_religions):  80%|████████  | 4/5 [00:55<00:11, 11.33s/it][INFO:swift] {'num_prompt_tokens': 834, 'num_generated_tokens': 1190, 'num_samples': 3, 'runtime': 20.01789139, 'samples/s': 0.14986593, 'tokens/s': 59.4468207}
INFO:     127.0.0.1:39598 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(world_religions): 100%|██████████| 5/5 [01:01<00:00,  9.40s/it]Predicting(world_religions): 100%|██████████| 5/5 [01:01<00:00, 12.28s/it]
2025-05-12 19:03:20,087 - evalscope - INFO - Dump predictions to /home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline/native/20250512_155825/predictions/Qwen2.5-3B/mmlu_world_religions.jsonl.
Reviewing(world_religions):   0%|          | 0/5 [00:00<?, ?it/s]Reviewing(world_religions): 100%|██████████| 5/5 [00:00<00:00, 62.50it/s]
Predicting(sociology):   0%|          | 0/5 [00:00<?, ?it/s][INFO:swift] {'num_prompt_tokens': 290, 'num_generated_tokens': 133, 'num_samples': 1, 'runtime': 20.02015299, 'samples/s': 0.04994967, 'tokens/s': 6.64330588}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01943812, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01980011, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.00804432, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:44920 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(sociology):  20%|██        | 1/5 [01:29<05:57, 89.38s/it][INFO:swift] {'num_prompt_tokens': 431, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.02016807, 'samples/s': 0.04994963, 'tokens/s': 102.29684352}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01707471, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.020063, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01749845, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.019695, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:44924 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(sociology):  40%|████      | 2/5 [02:58<04:28, 89.38s/it]INFO:     127.0.0.1:39598 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(sociology):  60%|██████    | 3/5 [03:00<01:38, 49.44s/it]INFO:     127.0.0.1:44940 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(sociology):  80%|████████  | 4/5 [03:07<00:32, 32.62s/it]INFO:     127.0.0.1:44956 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(sociology): 100%|██████████| 5/5 [03:13<00:00, 22.90s/it]Predicting(sociology): 100%|██████████| 5/5 [03:13<00:00, 38.64s/it]
2025-05-12 19:06:33,363 - evalscope - INFO - Dump predictions to /home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline/native/20250512_155825/predictions/Qwen2.5-3B/mmlu_sociology.jsonl.
Reviewing(sociology):   0%|          | 0/5 [00:00<?, ?it/s]Reviewing(sociology):  40%|████      | 2/5 [00:00<00:00, 14.33it/s]Reviewing(sociology): 100%|██████████| 5/5 [00:00<00:00, 10.57it/s]Reviewing(sociology): 100%|██████████| 5/5 [00:00<00:00, 10.90it/s]
Predicting(us_foreign_policy):   0%|          | 0/5 [00:00<?, ?it/s][INFO:swift] {'num_prompt_tokens': 1753, 'num_generated_tokens': 2350, 'num_samples': 4, 'runtime': 20.01959544, 'samples/s': 0.19980424, 'tokens/s': 117.38498946}
INFO:     127.0.0.1:44956 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(us_foreign_policy):  20%|██        | 1/5 [00:04<00:19,  4.98s/it]INFO:     127.0.0.1:38762 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(us_foreign_policy):  40%|████      | 2/5 [00:11<00:16,  5.63s/it][INFO:swift] {'num_prompt_tokens': 783, 'num_generated_tokens': 237, 'num_samples': 2, 'runtime': 20.02014956, 'samples/s': 0.09989935, 'tokens/s': 11.8380734}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01943056, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01758014, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:38764 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(us_foreign_policy):  60%|██████    | 3/5 [01:04<00:55, 27.68s/it]INFO:     127.0.0.1:38776 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(us_foreign_policy):  80%|████████  | 4/5 [01:11<00:19, 19.14s/it]INFO:     127.0.0.1:38780 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(us_foreign_policy): 100%|██████████| 5/5 [01:12<00:00, 12.84s/it]Predicting(us_foreign_policy): 100%|██████████| 5/5 [01:12<00:00, 14.54s/it]
2025-05-12 19:07:46,547 - evalscope - INFO - Dump predictions to /home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline/native/20250512_155825/predictions/Qwen2.5-3B/mmlu_us_foreign_policy.jsonl.
Reviewing(us_foreign_policy):   0%|          | 0/5 [00:00<?, ?it/s]Reviewing(us_foreign_policy):  80%|████████  | 4/5 [00:00<00:00, 36.53it/s]Reviewing(us_foreign_policy): 100%|██████████| 5/5 [00:00<00:00, 35.35it/s]
Predicting(high_school_macroeconomics):   0%|          | 0/5 [00:00<?, ?it/s]INFO:     127.0.0.1:38776 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_macroeconomics):  20%|██        | 1/5 [00:07<00:30,  7.56s/it][INFO:swift] {'num_prompt_tokens': 1572, 'num_generated_tokens': 1592, 'num_samples': 4, 'runtime': 20.01244893, 'samples/s': 0.19987559, 'tokens/s': 79.55048407}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01719115, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02011776, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01762784, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01766458, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:38780 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_macroeconomics):  40%|████      | 2/5 [01:36<02:46, 55.44s/it][INFO:swift] {'num_prompt_tokens': 347, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.01959134, 'samples/s': 0.04995107, 'tokens/s': 102.2997905}
INFO:     127.0.0.1:36662 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_macroeconomics):  60%|██████    | 3/5 [01:53<01:16, 38.08s/it]INFO:     127.0.0.1:36674 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_macroeconomics):  80%|████████  | 4/5 [02:08<00:28, 28.68s/it][INFO:swift] {'num_prompt_tokens': 643, 'num_generated_tokens': 732, 'num_samples': 2, 'runtime': 20.01981415, 'samples/s': 0.09990103, 'tokens/s': 36.56377599}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01987191, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.00904486, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02015104, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02014427, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:36680 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(high_school_macroeconomics): 100%|██████████| 5/5 [03:36<00:00, 50.35s/it]Predicting(high_school_macroeconomics): 100%|██████████| 5/5 [03:36<00:00, 43.39s/it]
2025-05-12 19:11:23,662 - evalscope - INFO - Dump predictions to /home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline/native/20250512_155825/predictions/Qwen2.5-3B/mmlu_high_school_macroeconomics.jsonl.
Reviewing(high_school_macroeconomics):   0%|          | 0/5 [00:00<?, ?it/s]Reviewing(high_school_macroeconomics):  40%|████      | 2/5 [00:00<00:00, 18.33it/s]Reviewing(high_school_macroeconomics):  80%|████████  | 4/5 [00:00<00:00, 16.82it/s]Reviewing(high_school_macroeconomics): 100%|██████████| 5/5 [00:00<00:00, 16.80it/s]
Predicting(computer_security):   0%|          | 0/5 [00:00<?, ?it/s]INFO:     127.0.0.1:36680 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(computer_security):  20%|██        | 1/5 [00:04<00:19,  4.90s/it][INFO:swift] {'num_prompt_tokens': 768, 'num_generated_tokens': 2148, 'num_samples': 2, 'runtime': 20.02014675, 'samples/s': 0.09989937, 'tokens/s': 107.29192081}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.00996017, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01915995, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02013122, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01526456, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:48986 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(computer_security):  40%|████      | 2/5 [01:34<02:44, 54.97s/it]INFO:     127.0.0.1:48994 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(computer_security):  60%|██████    | 3/5 [01:35<01:00, 30.15s/it]INFO:     127.0.0.1:49002 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(computer_security):  80%|████████  | 4/5 [01:36<00:18, 18.51s/it]INFO:     127.0.0.1:49006 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(computer_security): 100%|██████████| 5/5 [01:47<00:00, 15.81s/it]Predicting(computer_security): 100%|██████████| 5/5 [01:47<00:00, 21.45s/it]
2025-05-12 19:13:11,196 - evalscope - INFO - Dump predictions to /home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline/native/20250512_155825/predictions/Qwen2.5-3B/mmlu_computer_security.jsonl.
Reviewing(computer_security):   0%|          | 0/5 [00:00<?, ?it/s]Reviewing(computer_security):  60%|██████    | 3/5 [00:00<00:00, 26.89it/s]Reviewing(computer_security): 100%|██████████| 5/5 [00:00<00:00, 28.85it/s]
Predicting(moral_scenarios):   0%|          | 0/5 [00:00<?, ?it/s][INFO:swift] {'num_prompt_tokens': 1610, 'num_generated_tokens': 2308, 'num_samples': 4, 'runtime': 20.01984018, 'samples/s': 0.19980179, 'tokens/s': 115.28563562}
INFO:     127.0.0.1:45406 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(moral_scenarios):  20%|██        | 1/5 [00:06<00:26,  6.62s/it]INFO:     127.0.0.1:49006 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(moral_scenarios):  40%|████      | 2/5 [00:16<00:25,  8.47s/it][INFO:swift] {'num_prompt_tokens': 1204, 'num_generated_tokens': 352, 'num_samples': 2, 'runtime': 20.00733562, 'samples/s': 0.09996334, 'tokens/s': 17.59354702}
INFO:     127.0.0.1:45412 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(moral_scenarios):  60%|██████    | 3/5 [00:31<00:23, 11.58s/it][INFO:swift] {'num_prompt_tokens': 603, 'num_generated_tokens': 344, 'num_samples': 1, 'runtime': 20.01618538, 'samples/s': 0.04995957, 'tokens/s': 17.18609183}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02013402, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01946229, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.00138868, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:45422 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(moral_scenarios):  80%|████████  | 4/5 [02:02<00:42, 42.83s/it][INFO:swift] {'num_prompt_tokens': 599, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.02016325, 'samples/s': 0.04994964, 'tokens/s': 102.29686816}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01787091, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01982845, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.0201441, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01822858, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:45432 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(moral_scenarios): 100%|██████████| 5/5 [03:33<00:00, 60.25s/it]Predicting(moral_scenarios): 100%|██████████| 5/5 [03:33<00:00, 42.71s/it]
2025-05-12 19:16:44,927 - evalscope - INFO - Dump predictions to /home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline/native/20250512_155825/predictions/Qwen2.5-3B/mmlu_moral_scenarios.jsonl.
Reviewing(moral_scenarios):   0%|          | 0/5 [00:00<?, ?it/s]Reviewing(moral_scenarios): 100%|██████████| 5/5 [00:00<00:00, 126.81it/s]
Predicting(moral_disputes):   0%|          | 0/5 [00:00<?, ?it/s][INFO:swift] {'num_prompt_tokens': 629, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.02013715, 'samples/s': 0.04994971, 'tokens/s': 102.29700149}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02014947, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02013287, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.00106506, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:45432 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(moral_disputes):  20%|██        | 1/5 [01:29<05:57, 89.41s/it][INFO:swift] {'num_prompt_tokens': 414, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.02015029, 'samples/s': 0.04994967, 'tokens/s': 102.29693436}
INFO:     127.0.0.1:42942 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(moral_disputes):  40%|████      | 2/5 [01:37<02:03, 41.29s/it]INFO:     127.0.0.1:42946 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(moral_disputes):  60%|██████    | 3/5 [01:46<00:53, 26.59s/it][INFO:swift] {'num_prompt_tokens': 855, 'num_generated_tokens': 367, 'num_samples': 2, 'runtime': 20.01813266, 'samples/s': 0.09990942, 'tokens/s': 18.33337835}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01984552, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01978598, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02018245, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.0201448, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:42960 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(moral_disputes):  80%|████████  | 4/5 [03:15<00:51, 51.26s/it]INFO:     127.0.0.1:42962 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(moral_disputes): 100%|██████████| 5/5 [03:16<00:00, 33.14s/it]Predicting(moral_disputes): 100%|██████████| 5/5 [03:16<00:00, 39.24s/it]
2025-05-12 19:20:01,190 - evalscope - INFO - Dump predictions to /home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline/native/20250512_155825/predictions/Qwen2.5-3B/mmlu_moral_disputes.jsonl.
Reviewing(moral_disputes):   0%|          | 0/5 [00:00<?, ?it/s]Reviewing(moral_disputes):  60%|██████    | 3/5 [00:00<00:00, 20.07it/s]Reviewing(moral_disputes): 100%|██████████| 5/5 [00:00<00:00, 18.51it/s]
Predicting(electrical_engineering):   0%|          | 0/5 [00:00<?, ?it/s][INFO:swift] {'num_prompt_tokens': 820, 'num_generated_tokens': 2059, 'num_samples': 2, 'runtime': 20.02013868, 'samples/s': 0.09989941, 'tokens/s': 102.84644045}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02014286, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01700813, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02018839, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:42962 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(electrical_engineering):  20%|██        | 1/5 [01:29<05:59, 89.82s/it][INFO:swift] {'num_prompt_tokens': 471, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.01246325, 'samples/s': 0.04996886, 'tokens/s': 102.3362279}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01611717, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02016019, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02018768, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02017999, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:42960 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(electrical_engineering):  40%|████      | 2/5 [02:59<04:28, 89.54s/it][INFO:swift] {'num_prompt_tokens': 451, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.02015167, 'samples/s': 0.04994967, 'tokens/s': 102.29692731}
INFO:     127.0.0.1:41050 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(electrical_engineering):  60%|██████    | 3/5 [03:15<01:52, 56.21s/it][INFO:swift] {'num_prompt_tokens': 512, 'num_generated_tokens': 381, 'num_samples': 1, 'runtime': 20.02015405, 'samples/s': 0.04994967, 'tokens/s': 19.03082259}
INFO:     127.0.0.1:41064 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(electrical_engineering):  80%|████████  | 4/5 [03:50<00:47, 47.91s/it][INFO:swift] {'num_prompt_tokens': 442, 'num_generated_tokens': 823, 'num_samples': 1, 'runtime': 20.01220327, 'samples/s': 0.04996951, 'tokens/s': 41.12490708}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01715538, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01960328, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02010669, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.00383187, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:41078 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(electrical_engineering): 100%|██████████| 5/5 [05:20<00:00, 62.97s/it]Predicting(electrical_engineering): 100%|██████████| 5/5 [05:20<00:00, 64.11s/it]
2025-05-12 19:25:22,034 - evalscope - INFO - Dump predictions to /home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline/native/20250512_155825/predictions/Qwen2.5-3B/mmlu_electrical_engineering.jsonl.
Reviewing(electrical_engineering):   0%|          | 0/5 [00:00<?, ?it/s]Reviewing(electrical_engineering): 100%|██████████| 5/5 [00:00<00:00, 43.93it/s]Reviewing(electrical_engineering): 100%|██████████| 5/5 [00:00<00:00, 43.73it/s]
Predicting(astronomy):   0%|          | 0/5 [00:00<?, ?it/s]INFO:     127.0.0.1:41678 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(astronomy):  20%|██        | 1/5 [00:07<00:28,  7.13s/it][INFO:swift] {'num_prompt_tokens': 1007, 'num_generated_tokens': 2201, 'num_samples': 2, 'runtime': 20.02015684, 'samples/s': 0.09989932, 'tokens/s': 109.93919865}
INFO:     127.0.0.1:41684 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(astronomy):  40%|████      | 2/5 [00:16<00:25,  8.56s/it][INFO:swift] {'num_prompt_tokens': 566, 'num_generated_tokens': 207, 'num_samples': 1, 'runtime': 20.00385011, 'samples/s': 0.04999038, 'tokens/s': 10.34800795}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02016089, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02012583, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.0023335, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:41078 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(astronomy):  60%|██████    | 3/5 [01:46<01:31, 45.79s/it][INFO:swift] {'num_prompt_tokens': 528, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.02016021, 'samples/s': 0.04994965, 'tokens/s': 102.29688369}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01926136, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01423035, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02015864, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.0201696, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:41688 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(astronomy):  80%|████████  | 4/5 [03:17<01:03, 63.41s/it][INFO:swift] {'num_prompt_tokens': 538, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.02015765, 'samples/s': 0.04994966, 'tokens/s': 102.29689673}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02015292, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02011376, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02018197, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:41704 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(astronomy): 100%|██████████| 5/5 [04:47<00:00, 73.01s/it]Predicting(astronomy): 100%|██████████| 5/5 [04:47<00:00, 57.45s/it]
2025-05-12 19:30:09,401 - evalscope - INFO - Dump predictions to /home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline/native/20250512_155825/predictions/Qwen2.5-3B/mmlu_astronomy.jsonl.
Reviewing(astronomy):   0%|          | 0/5 [00:00<?, ?it/s]Reviewing(astronomy): 100%|██████████| 5/5 [00:00<00:00, 84.25it/s]
Predicting(college_biology):   0%|          | 0/5 [00:00<?, ?it/s][INFO:swift] {'num_prompt_tokens': 553, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.01110451, 'samples/s': 0.04997225, 'tokens/s': 102.34317643}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02014512, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01763439, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01763468, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01984303, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:41704 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(college_biology):  20%|██        | 1/5 [01:29<05:58, 89.67s/it][INFO:swift] {'num_prompt_tokens': 464, 'num_generated_tokens': 2048, 'num_samples': 1, 'runtime': 20.01950292, 'samples/s': 0.04995129, 'tokens/s': 102.30024233}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02014462, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.02013895, 'samples/s': 0.0, 'tokens/s': 0.0}
[INFO:swift] {'num_prompt_tokens': 0, 'num_generated_tokens': 0, 'num_samples': 0, 'runtime': 20.01122785, 'samples/s': 0.0, 'tokens/s': 0.0}
INFO:     127.0.0.1:43164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(college_biology):  40%|████      | 2/5 [02:59<04:28, 89.51s/it]INFO:     127.0.0.1:43172 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(college_biology):  60%|██████    | 3/5 [03:00<01:38, 49.20s/it]INFO:     127.0.0.1:43186 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(college_biology):  80%|████████  | 4/5 [03:05<00:31, 31.66s/it][INFO:swift] {'num_prompt_tokens': 1284, 'num_generated_tokens': 2169, 'num_samples': 3, 'runtime': 20.02015062, 'samples/s': 0.14984902, 'tokens/s': 108.34084324}
INFO:     127.0.0.1:43196 - "POST /v1/chat/completions HTTP/1.1" 200 OK
Predicting(college_biology): 100%|██████████| 5/5 [03:14<00:00, 23.61s/it]Predicting(college_biology): 100%|██████████| 5/5 [03:14<00:00, 38.88s/it]
2025-05-12 19:33:23,884 - evalscope - INFO - Dump predictions to /home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline/native/20250512_155825/predictions/Qwen2.5-3B/mmlu_college_biology.jsonl.
Reviewing(college_biology):   0%|          | 0/5 [00:00<?, ?it/s]Reviewing(college_biology):  80%|████████  | 4/5 [00:00<00:00, 32.44it/s]Reviewing(college_biology): 100%|██████████| 5/5 [00:00<00:00, 31.46it/s]
2025-05-12 19:33:24,229 - evalscope - INFO - Dump report: /home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline/native/20250512_155825/reports/Qwen2.5-3B/mmlu.json 

2025-05-12 19:33:24,298 - evalscope - INFO - Report table: 
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Model      | Dataset   | Metric          | Subset                              |   Num |   Score | Cat.0          |
+============+===========+=================+=====================================+=======+=========+================+
| Qwen2.5-3B | mmlu      | AverageAccuracy | high_school_european_history        |     5 |     0.4 | Humanities     |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | high_school_us_history              |     5 |     0.2 | Humanities     |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | high_school_world_history           |     5 |     0.2 | Humanities     |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | philosophy                          |     5 |     0.2 | Humanities     |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | prehistory                          |     5 |     0.8 | Humanities     |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | logical_fallacies                   |     5 |     0   | Humanities     |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | formal_logic                        |     5 |     0.4 | Humanities     |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | international_law                   |     5 |     0.2 | Humanities     |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | professional_law                    |     5 |     0.4 | Humanities     |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | jurisprudence                       |     5 |     0.4 | Humanities     |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | world_religions                     |     5 |     0.6 | Humanities     |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | moral_scenarios                     |     5 |     0.4 | Humanities     |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | moral_disputes                      |     5 |     0.6 | Humanities     |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | business_ethics                     |     5 |     0   | Other          |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | clinical_knowledge                  |     5 |     0.2 | Other          |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | medical_genetics                    |     5 |     0.4 | Other          |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | virology                            |     5 |     0   | Other          |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | professional_accounting             |     5 |     0   | Other          |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | professional_medicine               |     5 |     0.2 | Other          |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | nutrition                           |     5 |     0.4 | Other          |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | global_facts                        |     5 |     0.4 | Other          |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | anatomy                             |     5 |     0   | Other          |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | college_medicine                    |     5 |     0.8 | Other          |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | human_aging                         |     5 |     0.2 | Other          |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | miscellaneous                       |     5 |     0.6 | Other          |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | marketing                           |     5 |     0.8 | Other          |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | management                          |     5 |     0   | Other          |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | high_school_physics                 |     5 |     0   | STEM           |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | college_computer_science            |     5 |     0.4 | STEM           |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | high_school_biology                 |     5 |     0.4 | STEM           |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | abstract_algebra                    |     5 |     0.2 | STEM           |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | machine_learning                    |     5 |     0.4 | STEM           |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | college_chemistry                   |     5 |     0.4 | STEM           |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | elementary_mathematics              |     5 |     0.2 | STEM           |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | college_mathematics                 |     5 |     0   | STEM           |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | high_school_statistics              |     5 |     0.4 | STEM           |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | high_school_mathematics             |     5 |     0.4 | STEM           |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | high_school_computer_science        |     5 |     0.2 | STEM           |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | conceptual_physics                  |     5 |     0   | STEM           |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | high_school_chemistry               |     5 |     0.6 | STEM           |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | college_physics                     |     5 |     0.4 | STEM           |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | computer_security                   |     5 |     0.6 | STEM           |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | electrical_engineering              |     5 |     0   | STEM           |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | astronomy                           |     5 |     0.6 | STEM           |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | college_biology                     |     5 |     0.2 | STEM           |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | high_school_microeconomics          |     5 |     0.6 | Social Science |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | econometrics                        |     5 |     0.4 | Social Science |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | security_studies                    |     5 |     0   | Social Science |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | public_relations                    |     5 |     0.8 | Social Science |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | professional_psychology             |     5 |     0.4 | Social Science |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | human_sexuality                     |     5 |     0   | Social Science |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | high_school_government_and_politics |     5 |     0.6 | Social Science |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | high_school_geography               |     5 |     0.2 | Social Science |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | high_school_psychology              |     5 |     0.4 | Social Science |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | sociology                           |     5 |     0.2 | Social Science |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | us_foreign_policy                   |     5 |     0   | Social Science |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | high_school_macroeconomics          |     5 |     0.2 | Social Science |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+ 

2025-05-12 19:33:24,298 - evalscope - INFO - **** Evaluation finished on modelscope/mmlu ****

2025-05-12 19:33:24,301 - evalscope - INFO - Args: Task config is provided with TaskConfig type.
2025-05-12 19:33:24,301 - evalscope - INFO - **Loading task cfg for summarizer: {
    "model": "Qwen2.5-3B",
    "model_id": "Qwen2.5-3B",
    "model_args": {
        "revision": "master",
        "precision": "torch.float16"
    },
    "model_task": "text_generation",
    "template_type": null,
    "chat_template": null,
    "datasets": [
        "mmlu"
    ],
    "dataset_args": {
        "mmlu": {
            "name": "mmlu",
            "dataset_id": "modelscope/mmlu",
            "model_adapter": "generation",
            "output_types": [
                "multiple_choice_logits",
                "generation"
            ],
            "subset_list": [
                "high_school_european_history",
                "business_ethics",
                "clinical_knowledge",
                "medical_genetics",
                "high_school_us_history",
                "high_school_physics",
                "high_school_world_history",
                "virology",
                "high_school_microeconomics",
                "econometrics",
                "college_computer_science",
                "high_school_biology",
                "abstract_algebra",
                "professional_accounting",
                "philosophy",
                "professional_medicine",
                "nutrition",
                "global_facts",
                "machine_learning",
                "security_studies",
                "public_relations",
                "professional_psychology",
                "prehistory",
                "anatomy",
                "human_sexuality",
                "college_medicine",
                "high_school_government_and_politics",
                "college_chemistry",
                "logical_fallacies",
                "high_school_geography",
                "elementary_mathematics",
                "human_aging",
                "college_mathematics",
                "high_school_psychology",
                "formal_logic",
                "high_school_statistics",
                "international_law",
                "high_school_mathematics",
                "high_school_computer_science",
                "conceptual_physics",
                "miscellaneous",
                "high_school_chemistry",
                "marketing",
                "professional_law",
                "management",
                "college_physics",
                "jurisprudence",
                "world_religions",
                "sociology",
                "us_foreign_policy",
                "high_school_macroeconomics",
                "computer_security",
                "moral_scenarios",
                "moral_disputes",
                "electrical_engineering",
                "astronomy",
                "college_biology"
            ],
            "metric_list": [
                "AverageAccuracy"
            ],
            "few_shot_num": 5,
            "few_shot_random": false,
            "train_split": "train",
            "eval_split": "test",
            "prompt_template": "Answer the following multiple choice question about {subset_name}. The last line of your response should be of the following format: 'Answer: $LETTER' (without quotes) where LETTER is one of ABCD. Think step by step before answering.\n\n{query}",
            "system_prompt": null,
            "query_template": null,
            "pretty_name": "MMLU",
            "filters": null,
            "extra_params": {}
        }
    },
    "dataset_dir": "/home3/sgrf64/.cache/modelscope/hub/datasets",
    "dataset_hub": "modelscope",
    "generation_config": {
        "max_length": 2048,
        "max_new_tokens": 512,
        "do_sample": false,
        "top_k": 50,
        "top_p": 1.0,
        "temperature": 1.0
    },
    "eval_type": "service",
    "eval_backend": "Native",
    "eval_config": null,
    "stage": "all",
    "limit": 5,
    "eval_batch_size": 16,
    "mem_cache": false,
    "use_cache": null,
    "work_dir": "/home3/sgrf64/Project/qwen_finetune/eval_output/native/qwen2.5_3B_baseline/native/20250512_155825",
    "outputs": null,
    "debug": false,
    "dry_run": false,
    "seed": 42,
    "api_url": "http://127.0.0.1:8000/v1/chat/completions",
    "api_key": "EMPTY",
    "timeout": null,
    "stream": false,
    "judge_strategy": "auto",
    "judge_worker_num": 1,
    "judge_model_args": {}
}
2025-05-12 19:33:24,315 - evalscope - INFO - *** Report table ***
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Model      | Dataset   | Metric          | Subset                              |   Num |   Score | Cat.0          |
+============+===========+=================+=====================================+=======+=========+================+
| Qwen2.5-3B | mmlu      | AverageAccuracy | high_school_european_history        |     5 |     0.4 | Humanities     |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | high_school_us_history              |     5 |     0.2 | Humanities     |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | high_school_world_history           |     5 |     0.2 | Humanities     |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | philosophy                          |     5 |     0.2 | Humanities     |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | prehistory                          |     5 |     0.8 | Humanities     |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | logical_fallacies                   |     5 |     0   | Humanities     |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | formal_logic                        |     5 |     0.4 | Humanities     |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | international_law                   |     5 |     0.2 | Humanities     |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | professional_law                    |     5 |     0.4 | Humanities     |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | jurisprudence                       |     5 |     0.4 | Humanities     |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | world_religions                     |     5 |     0.6 | Humanities     |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | moral_scenarios                     |     5 |     0.4 | Humanities     |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | moral_disputes                      |     5 |     0.6 | Humanities     |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | business_ethics                     |     5 |     0   | Other          |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | clinical_knowledge                  |     5 |     0.2 | Other          |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | medical_genetics                    |     5 |     0.4 | Other          |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | virology                            |     5 |     0   | Other          |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | professional_accounting             |     5 |     0   | Other          |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | professional_medicine               |     5 |     0.2 | Other          |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | nutrition                           |     5 |     0.4 | Other          |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | global_facts                        |     5 |     0.4 | Other          |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | anatomy                             |     5 |     0   | Other          |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | college_medicine                    |     5 |     0.8 | Other          |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | human_aging                         |     5 |     0.2 | Other          |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | miscellaneous                       |     5 |     0.6 | Other          |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | marketing                           |     5 |     0.8 | Other          |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | management                          |     5 |     0   | Other          |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | high_school_physics                 |     5 |     0   | STEM           |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | college_computer_science            |     5 |     0.4 | STEM           |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | high_school_biology                 |     5 |     0.4 | STEM           |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | abstract_algebra                    |     5 |     0.2 | STEM           |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | machine_learning                    |     5 |     0.4 | STEM           |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | college_chemistry                   |     5 |     0.4 | STEM           |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | elementary_mathematics              |     5 |     0.2 | STEM           |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | college_mathematics                 |     5 |     0   | STEM           |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | high_school_statistics              |     5 |     0.4 | STEM           |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | high_school_mathematics             |     5 |     0.4 | STEM           |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | high_school_computer_science        |     5 |     0.2 | STEM           |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | conceptual_physics                  |     5 |     0   | STEM           |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | high_school_chemistry               |     5 |     0.6 | STEM           |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | college_physics                     |     5 |     0.4 | STEM           |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | computer_security                   |     5 |     0.6 | STEM           |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | electrical_engineering              |     5 |     0   | STEM           |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | astronomy                           |     5 |     0.6 | STEM           |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | college_biology                     |     5 |     0.2 | STEM           |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | high_school_microeconomics          |     5 |     0.6 | Social Science |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | econometrics                        |     5 |     0.4 | Social Science |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | security_studies                    |     5 |     0   | Social Science |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | public_relations                    |     5 |     0.8 | Social Science |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | professional_psychology             |     5 |     0.4 | Social Science |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | human_sexuality                     |     5 |     0   | Social Science |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | high_school_government_and_politics |     5 |     0.6 | Social Science |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | high_school_geography               |     5 |     0.2 | Social Science |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | high_school_psychology              |     5 |     0.4 | Social Science |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | sociology                           |     5 |     0.2 | Social Science |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | us_foreign_policy                   |     5 |     0   | Social Science |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
| Qwen2.5-3B | mmlu      | AverageAccuracy | high_school_macroeconomics          |     5 |     0.2 | Social Science |
+------------+-----------+-----------------+-------------------------------------+-------+---------+----------------+
[INFO:swift] The deployment process has been terminated.
[INFO:swift] The eval result have been saved to result_jsonl: `/home3/sgrf64/Project/qwen_finetune/result/Qwen2.5-3B/eval_result.jsonl`.
[INFO:swift] End time of running main: 2025-05-12 19:33:24.345928
INFO:     Shutting down
INFO:     Waiting for application shutdown.
[INFO:swift] {'num_prompt_tokens': 442, 'num_generated_tokens': 210, 'num_samples': 1, 'runtime': 7.9453444, 'samples/s': 0.12585987, 'tokens/s': 26.43057234}
INFO:     Application shutdown complete.
INFO:     Finished server process [3156197]
/usr/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
